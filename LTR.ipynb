{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78d4e0-4f6d-4402-944d-b45d1cd41cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df59358-c241-47ed-ac1b-08fa5a5798ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q tensorflow_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "882de103-0423-443b-ba22-51ce6984eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "PATH = os.getcwd()\n",
    "#PATH = '/content/drive/Shareddrives/Master Tesis/Tesis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f6fca1fd-c334-453b-987f-e17862bb101f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>big_log_ret</th>\n",
       "      <th>big_RCV</th>\n",
       "      <th>big_RVT</th>\n",
       "      <th>big_positivePartscr</th>\n",
       "      <th>big_negativePartscr</th>\n",
       "      <th>big_splogscr</th>\n",
       "      <th>big_linscr</th>\n",
       "      <th>big_lag1_log_ret</th>\n",
       "      <th>big_lag4_log_ret</th>\n",
       "      <th>big_lag1_month_log_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AAL</td>\n",
       "      <td>0.063980</td>\n",
       "      <td>8.476000</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>54.733580</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>0.094986</td>\n",
       "      <td>-0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.006150</td>\n",
       "      <td>13.162167</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.015650</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>48.380133</td>\n",
       "      <td>0.042066</td>\n",
       "      <td>-0.032534</td>\n",
       "      <td>0.070567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-0.020683</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>65.547120</td>\n",
       "      <td>0.036953</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.059249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>ABT</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>-24.607200</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>-0.012980</td>\n",
       "      <td>27.375300</td>\n",
       "      <td>-0.006602</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.023364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>-3.370000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.024640</td>\n",
       "      <td>40.688020</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>-0.062913</td>\n",
       "      <td>-0.055493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42050</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>UPS</td>\n",
       "      <td>-0.022512</td>\n",
       "      <td>-42.160333</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>-0.008817</td>\n",
       "      <td>46.677617</td>\n",
       "      <td>-0.015323</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>-0.034095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42051</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>USB</td>\n",
       "      <td>-0.033782</td>\n",
       "      <td>-28.514833</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.037033</td>\n",
       "      <td>68.229333</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>-0.048707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42052</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>VZ</td>\n",
       "      <td>-0.007363</td>\n",
       "      <td>-22.016000</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>0.036629</td>\n",
       "      <td>-0.066443</td>\n",
       "      <td>28.958114</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>-0.014255</td>\n",
       "      <td>-0.022713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42053</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>WFC</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-37.779000</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>-0.061550</td>\n",
       "      <td>15.077883</td>\n",
       "      <td>-0.008021</td>\n",
       "      <td>-0.010320</td>\n",
       "      <td>-0.050985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42054</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>WMT</td>\n",
       "      <td>-0.052347</td>\n",
       "      <td>-12.486143</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.020143</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>-0.029786</td>\n",
       "      <td>50.108929</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>-0.030717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42055 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Query Ticker  big_log_ret    big_RCV   big_RVT  \\\n",
       "0      2012-01-08    AAL     0.063980   8.476000  0.000280   \n",
       "1      2012-01-08   AAPL    -0.006150  13.162167  0.003400   \n",
       "2      2012-01-08    ABC    -0.020683   0.404000  0.000760   \n",
       "3      2012-01-08    ABT     0.000864 -24.607200  0.000320   \n",
       "4      2012-01-08   AMZN    -0.023212  -3.370000  0.001100   \n",
       "...           ...    ...          ...        ...       ...   \n",
       "42050  2021-11-28    UPS    -0.022512 -42.160333  0.000317   \n",
       "42051  2021-11-28    USB    -0.033782 -28.514833  0.000483   \n",
       "42052  2021-11-28     VZ    -0.007363 -22.016000  0.000686   \n",
       "42053  2021-11-28    WFC    -0.014140 -37.779000  0.000983   \n",
       "42054  2021-11-28    WMT    -0.052347 -12.486143  0.000643   \n",
       "\n",
       "       big_positivePartscr  big_negativePartscr  big_splogscr  big_linscr  \\\n",
       "0                 0.020240             0.013340      0.010760   54.733580   \n",
       "1                 0.016050             0.015650      0.020333   48.380133   \n",
       "2                 0.027820             0.012980      0.017000   65.547120   \n",
       "3                 0.010820             0.018540     -0.012980   27.375300   \n",
       "4                 0.016180             0.020000     -0.024640   40.688020   \n",
       "...                    ...                  ...           ...         ...   \n",
       "42050             0.018200             0.024717     -0.008817   46.677617   \n",
       "42051             0.020517             0.010367      0.037033   68.229333   \n",
       "42052             0.018957             0.036629     -0.066443   28.958114   \n",
       "42053             0.004283             0.017333     -0.061550   15.077883   \n",
       "42054             0.020143             0.027329     -0.029786   50.108929   \n",
       "\n",
       "       big_lag1_log_ret  big_lag4_log_ret  big_lag1_month_log_ret  \n",
       "0              0.099426          0.094986               -0.003565  \n",
       "1              0.042066         -0.032534                0.070567  \n",
       "2              0.036953          0.010394                0.059249  \n",
       "3             -0.006602          0.005847                0.023364  \n",
       "4              0.053483         -0.062913               -0.055493  \n",
       "...                 ...               ...                     ...  \n",
       "42050         -0.015323         -0.024901               -0.034095  \n",
       "42051         -0.001564          0.005287               -0.048707  \n",
       "42052          0.018313         -0.014255               -0.022713  \n",
       "42053         -0.008021         -0.010320               -0.050985  \n",
       "42054          0.017474          0.005406               -0.030717  \n",
       "\n",
       "[42055 rows x 12 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_ranking as tfr\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import input_pb2\n",
    "\n",
    "final_table = pd.read_csv(os.path.join(PATH, 'Tables', 'final_table.csv'))\n",
    "final_table['Query'] = pd.to_datetime(final_table['Query']).dt.date\n",
    "final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8c4b993f-93d3-42da-80a4-6e68cc411227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the paths to files containing training and test instances.\n",
    "_TRAIN_DATA_PATH = \"./Dataset-tfrecords/70v30Split/train.tfrecord\"\n",
    "_VALID_DATA_PATH =  \"./Dataset-tfrecords/70v30Split/test.tfrecord\"\n",
    "\n",
    "# The maximum number of documents per query in the dataset.\n",
    "# Document lists are padded or truncated to this size.\n",
    "_LIST_SIZE = 108 #For each query we will be taking the max number of docs/companies - 108\n",
    "\n",
    "# The document relevance label in the tf-records.\n",
    "_LABEL_FEATURE_NAME = \"rel\"\n",
    "_NAME_FEATURES = ['big_RCV', 'big_RVT', 'big_positivePartscr', 'big_negativePartscr',\n",
    "                  'big_splogscr', 'big_linscr', 'big_lag1_log_ret', 'big_lag4_log_ret',\n",
    "                  'big_lag1_month_log_ret'] #Name of the doc features (\"doc id\" and \"rel\" are not features)\n",
    "_NUM_FEATURES = len(_NAME_FEATURES)\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "\n",
    "# Learning rate for optimizer.\n",
    "_LEARNING_RATE = 0.05\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 32\n",
    "_DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389ab12-64d0-4f39-876b-bb4325154750",
   "metadata": {},
   "source": [
    "### Creating input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "45798f32-6062-48c5-9958-3e7429a1ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_columns():\n",
    "    '''\n",
    "    This function specifies Features via Feature Columns: (see https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html)\n",
    "\n",
    "    Feature Columns are TensorFlow abstractions that are used to capture rich information about each feature.\n",
    "    It allows for easy transformations for a diverse range of raw features and for interfacing with Estimators.\n",
    "    Specifying the feature columns (and optionally, their transformaitons) is necessary to provide the parsing specifications.\n",
    "\n",
    "    Consistent with our input formats for ranking, such as ELWC format, we create feature columns for context features \n",
    "    and example features.\n",
    "    '''\n",
    "    # We dont have context features in in our datasets (query id is not a feature)\n",
    "    context_feature_columns = {}\n",
    "    \n",
    "    #Specifying the features that we will take from our ELWC, and their transformations (in our case all are numeric, so no transformations)\n",
    "    feature_names = _NAME_FEATURES\n",
    "    example_feature_columns = {\n",
    "        name:\n",
    "        tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n",
    "        for name in feature_names}\n",
    "    \n",
    "    return context_feature_columns, example_feature_columns\n",
    "\n",
    "\n",
    "def create_dataset_from_tfrecords(input_path:str,\n",
    "                                  batch_sz:int,\n",
    "                                  list_sz:int,\n",
    "                                  shuffle:bool = False,\n",
    "                                  num_epochs:int = None,\n",
    "                                  data_format:str = \"ELWC\",\n",
    "                                  compression_type:str = ''):\n",
    "    '''\n",
    "    Function to read ELWC tfrecords and convert them into a Ranking Dataset according to the parsing specs described in the next lines\n",
    "    '''\n",
    "    \n",
    "    #Specify the TensorFlow abstractions of each feature inside context and example dictionaries\n",
    "    context_feature_columns, example_feature_columns = create_feature_columns()\n",
    "\n",
    "    #Create parsing spec dictionary from input feature_columns. The returned dictionary can be used as arg in\n",
    "    #tfr.dataset.build_ranking_dataset and specifies how it should parse the document in \"file_pattern\" argument\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(context_feature_columns.values())\n",
    "    label_column = tf.feature_column.numeric_column(_LABEL_FEATURE_NAME, dtype=tf.float32, default_value=_PADDING_LABEL)\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(list(example_feature_columns.values()) + [label_column])\n",
    "    \n",
    "    #Define the \"reader_args\" that we'll pass to tfr.dataset.build_ranking_dataset to specify the compression type\n",
    "    _reader_arg_list = []\n",
    "    if compression_type:\n",
    "        assert compression_type in [\"\", \"GZIP\",\"ZLIB\"]\n",
    "        _reader_arg_list = [compression_type]\n",
    "\n",
    "    #Build Ranking Dataset\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "      file_pattern=input_path,\n",
    "      data_format=tfr.data.ELWC,\n",
    "      batch_size=batch_sz, #Rate at which we read our data into our model from file\n",
    "      list_size=list_sz, #Amount of docs we will take for each query - in our case we take all companies\n",
    "      context_feature_spec=context_feature_spec,\n",
    "      example_feature_spec=example_feature_spec,\n",
    "      reader=tf.data.TFRecordDataset,\n",
    "      reader_args= _reader_arg_list,\n",
    "      shuffle=shuffle, #Whether to shuffle the examples before taking them\n",
    "      num_epochs=num_epochs,\n",
    "      )\n",
    "    \n",
    "    #Define additional transformations we might want to apply to our features\n",
    "    def _log1p_transform(features):\n",
    "        '''\n",
    "        computes elementwise log_e(|x|)*sign(x)\n",
    "        '''\n",
    "        transformed_feats = {\n",
    "            f:tf.math.multiply(\n",
    "                tf.math.log1p(\n",
    "                    tf.math.abs(features[f])\n",
    "                    ),\n",
    "                tf.math.sign(features[f])\n",
    "                )\n",
    "            for f in features}\n",
    "        return transformed_feats\n",
    "\n",
    "    def _split_label_and_transform_features(features):\n",
    "        label = tf.squeeze(features.pop(_LABEL_FEATURE_NAME), axis=2)\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        features = features #_log1p_transform(features)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "    dataset = dataset.map(_split_label_and_transform_features)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "67fca737-0a5c-4b8b-95c7-a2675a281e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset_from_tfrecords(_TRAIN_DATA_PATH,\n",
    "                                              _BATCH_SIZE,\n",
    "                                              _LIST_SIZE,\n",
    "                                              compression_type=\"\")\n",
    "\n",
    "vali_dataset = create_dataset_from_tfrecords(_VALID_DATA_PATH,\n",
    "                                             _BATCH_SIZE,\n",
    "                                             _LIST_SIZE,\n",
    "                                             shuffle=False,\n",
    "                                             num_epochs=1, \n",
    "                                             compression_type=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb5158-905e-4992-84a2-a8867c89a9e2",
   "metadata": {},
   "source": [
    "### Defining Loss function and evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c0f17-cc84-4a1a-b68e-c23aa2863837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loss and the evaluation functions will be passed to Keras when we build our Model\n",
    "\n",
    "#Loss:\n",
    "#Different Losses knowing that the softmax loss is representative of the ListNet apporach\n",
    "_loss_obj = tfr.keras.losses.get(tfr.losses.RankingLossKey.SOFTMAX_LOSS) # Contains all ranking metrics, including NDCG @ {1, 3, 5, 10}.\n",
    "#_loss_obj = tfr.keras.losses.get(tfr.losses.RankingLossKey.UNIQUE_SOFTMAX_LOSS)\n",
    "#_loss_obj = tfr.keras.losses.get(tfr.losses.RankingLossKey.LIST_MLE_LOSS)\n",
    "\n",
    "#Evaluation metrics:\n",
    "def _make_eval_metric_fns():\n",
    "    \"\"\"Returns a list of ranking metrics for the keras ranker\"\"\"\n",
    "    metric_fns = [tfr.keras.metrics.get(**kwargs) \n",
    "                        for kwargs in [dict(key=\"ndcg\", topn=topn, \n",
    "                                        name=\"metric/ndcg_{}\".format(topn)) \n",
    "                                            for topn in [1, 3, 5, 10]]\n",
    "                ]\n",
    "    return metric_fns\n",
    "\n",
    "default_metrics = _make_eval_metric_fns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71dcf4-626f-453b-8bc2-8837b5bcdf38",
   "metadata": {},
   "source": [
    "### Create TensorFlow model - Using pre-made (canned) Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5c6c2f77-f0a5-4724-a2c5-d7e9a6ad6566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.feature_columns specifications can be passed to the \"feature_columns\" argument of our DNN Estimator, when we instanciate it \n",
    "context_feature_columns, example_feature_columns = create_feature_columns()\n",
    "\n",
    "# Using a Canned Network - (See to know about Estimators: https://developers.googleblog.com/2017/09/introducing-tensorflow-datasets.html)\n",
    "ranking_network = tfr.keras.canned.DNNRankingNetwork(\n",
    "      context_feature_columns=context_feature_columns,\n",
    "      example_feature_columns=example_feature_columns,\n",
    "      hidden_layer_dims=[64, 24, 10],\n",
    "      activation=tf.nn.relu,\n",
    "      dropout=_DROPOUT_RATE,\n",
    "      use_batch_norm=True,\n",
    "      batch_norm_moment=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c464bedd-8257-4b31-95e0-b29b27e967e8",
   "metadata": {},
   "source": [
    "### Putting It All Together in a Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "86499e15-7e40-4249-bbb6-2ec3cc1a565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ranker as a Functional Keras model.\n",
    "ranker = tfr.keras.model.create_keras_model(network=ranking_network,\n",
    "                                            loss=_loss_obj,\n",
    "                                            metrics=default_metrics,\n",
    "                                            optimizer=tf.keras.optimizers.Adagrad(learning_rate=_LEARNING_RATE),\n",
    "                                            size_feature_name=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f41e9-35f4-48ee-acd9-71e56fb36024",
   "metadata": {},
   "source": [
    "### Additional run config parameters for our Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6907d3e7-9816-4d72-9494-818e54906925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not necessary unless you want to create an Estimator out of the model we will create in the next cell by using tfr.keras.estimator.model_to_estimator\n",
    "run_config = tf.estimator.RunConfig(\n",
    "      model_dir=_MODEL_DIR,\n",
    "      keep_checkpoint_max=10,\n",
    "      save_checkpoints_secs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f629700f-91f5-4cdb-8874-5523cdcb1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where we save the log records of the training and validation.\n",
    "_MODEL_DIR = f\"./Models/model_{dt.datetime.now().strftime('%Y-%m-%d_%H-%M')}\"\n",
    "\n",
    "\n",
    "# setting as shell env for tensorboard stuff\n",
    "os.environ[\"models_dir\"] = _MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f80a00f3-b91a-405a-a3d6-fed0e6acfcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.2583 - metric/ndcg_1: 0.3905 - metric/ndcg_3: 0.4402 - metric/ndcg_5: 0.4716 - metric/ndcg_10: 0.5246 - val_loss: 4.8211 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5374 - val_metric/ndcg_5: 0.5318 - val_metric/ndcg_10: 0.5745\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.2668 - metric/ndcg_1: 0.3869 - metric/ndcg_3: 0.4419 - metric/ndcg_5: 0.4739 - metric/ndcg_10: 0.5269 - val_loss: 4.8216 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5374 - val_metric/ndcg_5: 0.5322 - val_metric/ndcg_10: 0.5731\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 4.2585 - metric/ndcg_1: 0.3931 - metric/ndcg_3: 0.4469 - metric/ndcg_5: 0.4769 - metric/ndcg_10: 0.5285 - val_loss: 4.8247 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5316 - val_metric/ndcg_5: 0.5354 - val_metric/ndcg_10: 0.5751\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2658 - metric/ndcg_1: 0.3938 - metric/ndcg_3: 0.4431 - metric/ndcg_5: 0.4742 - metric/ndcg_10: 0.5262 - val_loss: 4.8195 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5374 - val_metric/ndcg_5: 0.5325 - val_metric/ndcg_10: 0.5723\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 4.2537 - metric/ndcg_1: 0.3852 - metric/ndcg_3: 0.4410 - metric/ndcg_5: 0.4709 - metric/ndcg_10: 0.5242 - val_loss: 4.8203 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5407 - val_metric/ndcg_5: 0.5349 - val_metric/ndcg_10: 0.5768\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2544 - metric/ndcg_1: 0.3892 - metric/ndcg_3: 0.4411 - metric/ndcg_5: 0.4723 - metric/ndcg_10: 0.5246 - val_loss: 4.8217 - val_metric/ndcg_1: 0.5250 - val_metric/ndcg_3: 0.5405 - val_metric/ndcg_5: 0.5420 - val_metric/ndcg_10: 0.5810\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2406 - metric/ndcg_1: 0.3868 - metric/ndcg_3: 0.4415 - metric/ndcg_5: 0.4728 - metric/ndcg_10: 0.5259 - val_loss: 4.8223 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5308 - val_metric/ndcg_5: 0.5299 - val_metric/ndcg_10: 0.5757\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2540 - metric/ndcg_1: 0.3903 - metric/ndcg_3: 0.4392 - metric/ndcg_5: 0.4713 - metric/ndcg_10: 0.5245 - val_loss: 4.8210 - val_metric/ndcg_1: 0.5225 - val_metric/ndcg_3: 0.5434 - val_metric/ndcg_5: 0.5339 - val_metric/ndcg_10: 0.5835\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2599 - metric/ndcg_1: 0.3948 - metric/ndcg_3: 0.4434 - metric/ndcg_5: 0.4742 - metric/ndcg_10: 0.5273 - val_loss: 4.8198 - val_metric/ndcg_1: 0.5298 - val_metric/ndcg_3: 0.5476 - val_metric/ndcg_5: 0.5386 - val_metric/ndcg_10: 0.5812\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2646 - metric/ndcg_1: 0.3974 - metric/ndcg_3: 0.4440 - metric/ndcg_5: 0.4752 - metric/ndcg_10: 0.5280 - val_loss: 4.8235 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5322 - val_metric/ndcg_5: 0.5321 - val_metric/ndcg_10: 0.5761\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2572 - metric/ndcg_1: 0.3941 - metric/ndcg_3: 0.4424 - metric/ndcg_5: 0.4735 - metric/ndcg_10: 0.5271 - val_loss: 4.8194 - val_metric/ndcg_1: 0.5021 - val_metric/ndcg_3: 0.5462 - val_metric/ndcg_5: 0.5357 - val_metric/ndcg_10: 0.5825\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.2577 - metric/ndcg_1: 0.3961 - metric/ndcg_3: 0.4429 - metric/ndcg_5: 0.4741 - metric/ndcg_10: 0.5284 - val_loss: 4.8190 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5423 - val_metric/ndcg_5: 0.5345 - val_metric/ndcg_10: 0.5734\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2614 - metric/ndcg_1: 0.4005 - metric/ndcg_3: 0.4426 - metric/ndcg_5: 0.4737 - metric/ndcg_10: 0.5275 - val_loss: 4.8211 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5333 - val_metric/ndcg_5: 0.5379 - val_metric/ndcg_10: 0.5766\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2424 - metric/ndcg_1: 0.3934 - metric/ndcg_3: 0.4418 - metric/ndcg_5: 0.4742 - metric/ndcg_10: 0.5287 - val_loss: 4.8226 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5374 - val_metric/ndcg_5: 0.5391 - val_metric/ndcg_10: 0.5753\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2435 - metric/ndcg_1: 0.3941 - metric/ndcg_3: 0.4421 - metric/ndcg_5: 0.4737 - metric/ndcg_10: 0.5263 - val_loss: 4.8204 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5398 - val_metric/ndcg_5: 0.5297 - val_metric/ndcg_10: 0.5795\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2591 - metric/ndcg_1: 0.3940 - metric/ndcg_3: 0.4450 - metric/ndcg_5: 0.4758 - metric/ndcg_10: 0.5270 - val_loss: 4.8199 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5399 - val_metric/ndcg_5: 0.5292 - val_metric/ndcg_10: 0.5736\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2624 - metric/ndcg_1: 0.4024 - metric/ndcg_3: 0.4482 - metric/ndcg_5: 0.4785 - metric/ndcg_10: 0.5289 - val_loss: 4.8221 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5386 - val_metric/ndcg_5: 0.5288 - val_metric/ndcg_10: 0.5733\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2622 - metric/ndcg_1: 0.3983 - metric/ndcg_3: 0.4445 - metric/ndcg_5: 0.4756 - metric/ndcg_10: 0.5292 - val_loss: 4.8209 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5401 - val_metric/ndcg_5: 0.5353 - val_metric/ndcg_10: 0.5774\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2616 - metric/ndcg_1: 0.3959 - metric/ndcg_3: 0.4444 - metric/ndcg_5: 0.4740 - metric/ndcg_10: 0.5272 - val_loss: 4.8201 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5391 - val_metric/ndcg_5: 0.5338 - val_metric/ndcg_10: 0.5754\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2587 - metric/ndcg_1: 0.3879 - metric/ndcg_3: 0.4405 - metric/ndcg_5: 0.4725 - metric/ndcg_10: 0.5246 - val_loss: 4.8205 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5376 - val_metric/ndcg_5: 0.5321 - val_metric/ndcg_10: 0.5701\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 4.2456 - metric/ndcg_1: 0.3923 - metric/ndcg_3: 0.4427 - metric/ndcg_5: 0.4748 - metric/ndcg_10: 0.5260 - val_loss: 4.8226 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5317 - val_metric/ndcg_5: 0.5306 - val_metric/ndcg_10: 0.5742\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 4.2440 - metric/ndcg_1: 0.3893 - metric/ndcg_3: 0.4406 - metric/ndcg_5: 0.4738 - metric/ndcg_10: 0.5266 - val_loss: 4.8226 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5321 - val_metric/ndcg_5: 0.5319 - val_metric/ndcg_10: 0.5783\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.2529 - metric/ndcg_1: 0.3884 - metric/ndcg_3: 0.4405 - metric/ndcg_5: 0.4718 - metric/ndcg_10: 0.5251 - val_loss: 4.8205 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5389 - val_metric/ndcg_5: 0.5335 - val_metric/ndcg_10: 0.5737\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.2671 - metric/ndcg_1: 0.3914 - metric/ndcg_3: 0.4425 - metric/ndcg_5: 0.4746 - metric/ndcg_10: 0.5261 - val_loss: 4.8221 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5391 - val_metric/ndcg_5: 0.5325 - val_metric/ndcg_10: 0.5761\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2617 - metric/ndcg_1: 0.3948 - metric/ndcg_3: 0.4479 - metric/ndcg_5: 0.4771 - metric/ndcg_10: 0.5293 - val_loss: 4.8239 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5284 - val_metric/ndcg_5: 0.5316 - val_metric/ndcg_10: 0.5747\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2607 - metric/ndcg_1: 0.3890 - metric/ndcg_3: 0.4393 - metric/ndcg_5: 0.4731 - metric/ndcg_10: 0.5248 - val_loss: 4.8196 - val_metric/ndcg_1: 0.4720 - val_metric/ndcg_3: 0.5317 - val_metric/ndcg_5: 0.5287 - val_metric/ndcg_10: 0.5709\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2540 - metric/ndcg_1: 0.3901 - metric/ndcg_3: 0.4416 - metric/ndcg_5: 0.4723 - metric/ndcg_10: 0.5266 - val_loss: 4.8193 - val_metric/ndcg_1: 0.4997 - val_metric/ndcg_3: 0.5388 - val_metric/ndcg_5: 0.5343 - val_metric/ndcg_10: 0.5730\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.2599 - metric/ndcg_1: 0.3949 - metric/ndcg_3: 0.4473 - metric/ndcg_5: 0.4781 - metric/ndcg_10: 0.5292 - val_loss: 4.8215 - val_metric/ndcg_1: 0.4955 - val_metric/ndcg_3: 0.5349 - val_metric/ndcg_5: 0.5368 - val_metric/ndcg_10: 0.5747\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2366 - metric/ndcg_1: 0.3950 - metric/ndcg_3: 0.4420 - metric/ndcg_5: 0.4731 - metric/ndcg_10: 0.5267 - val_loss: 4.8231 - val_metric/ndcg_1: 0.5004 - val_metric/ndcg_3: 0.5319 - val_metric/ndcg_5: 0.5376 - val_metric/ndcg_10: 0.5767\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2510 - metric/ndcg_1: 0.3966 - metric/ndcg_3: 0.4432 - metric/ndcg_5: 0.4745 - metric/ndcg_10: 0.5253 - val_loss: 4.8207 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5370 - val_metric/ndcg_5: 0.5280 - val_metric/ndcg_10: 0.5751\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2588 - metric/ndcg_1: 0.3949 - metric/ndcg_3: 0.4452 - metric/ndcg_5: 0.4750 - metric/ndcg_10: 0.5297 - val_loss: 4.8196 - val_metric/ndcg_1: 0.5298 - val_metric/ndcg_3: 0.5482 - val_metric/ndcg_5: 0.5389 - val_metric/ndcg_10: 0.5787\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2657 - metric/ndcg_1: 0.3896 - metric/ndcg_3: 0.4431 - metric/ndcg_5: 0.4755 - metric/ndcg_10: 0.5274 - val_loss: 4.8234 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5317 - val_metric/ndcg_5: 0.5276 - val_metric/ndcg_10: 0.5752\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2551 - metric/ndcg_1: 0.3825 - metric/ndcg_3: 0.4391 - metric/ndcg_5: 0.4723 - metric/ndcg_10: 0.5247 - val_loss: 4.8201 - val_metric/ndcg_1: 0.5298 - val_metric/ndcg_3: 0.5464 - val_metric/ndcg_5: 0.5364 - val_metric/ndcg_10: 0.5791\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2587 - metric/ndcg_1: 0.3952 - metric/ndcg_3: 0.4465 - metric/ndcg_5: 0.4770 - metric/ndcg_10: 0.5295 - val_loss: 4.8196 - val_metric/ndcg_1: 0.5250 - val_metric/ndcg_3: 0.5493 - val_metric/ndcg_5: 0.5406 - val_metric/ndcg_10: 0.5818\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2600 - metric/ndcg_1: 0.3972 - metric/ndcg_3: 0.4468 - metric/ndcg_5: 0.4764 - metric/ndcg_10: 0.5273 - val_loss: 4.8209 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5349 - val_metric/ndcg_5: 0.5347 - val_metric/ndcg_10: 0.5717\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2428 - metric/ndcg_1: 0.3957 - metric/ndcg_3: 0.4452 - metric/ndcg_5: 0.4734 - metric/ndcg_10: 0.5266 - val_loss: 4.8236 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5339 - val_metric/ndcg_5: 0.5329 - val_metric/ndcg_10: 0.5724\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2416 - metric/ndcg_1: 0.3967 - metric/ndcg_3: 0.4430 - metric/ndcg_5: 0.4747 - metric/ndcg_10: 0.5281 - val_loss: 4.8205 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5405 - val_metric/ndcg_5: 0.5337 - val_metric/ndcg_10: 0.5751\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2608 - metric/ndcg_1: 0.3959 - metric/ndcg_3: 0.4423 - metric/ndcg_5: 0.4750 - metric/ndcg_10: 0.5283 - val_loss: 4.8204 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5393 - val_metric/ndcg_5: 0.5323 - val_metric/ndcg_10: 0.5713\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2663 - metric/ndcg_1: 0.3922 - metric/ndcg_3: 0.4450 - metric/ndcg_5: 0.4760 - metric/ndcg_10: 0.5272 - val_loss: 4.8216 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5342 - val_metric/ndcg_5: 0.5323 - val_metric/ndcg_10: 0.5773\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2579 - metric/ndcg_1: 0.3881 - metric/ndcg_3: 0.4416 - metric/ndcg_5: 0.4727 - metric/ndcg_10: 0.5252 - val_loss: 4.8216 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5367 - val_metric/ndcg_5: 0.5328 - val_metric/ndcg_10: 0.5763\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2619 - metric/ndcg_1: 0.3917 - metric/ndcg_3: 0.4422 - metric/ndcg_5: 0.4739 - metric/ndcg_10: 0.5289 - val_loss: 4.8203 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5395 - val_metric/ndcg_5: 0.5336 - val_metric/ndcg_10: 0.5707\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 4.2553 - metric/ndcg_1: 0.3977 - metric/ndcg_3: 0.4415 - metric/ndcg_5: 0.4720 - metric/ndcg_10: 0.5253 - val_loss: 4.8206 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5369 - val_metric/ndcg_5: 0.5344 - val_metric/ndcg_10: 0.5721\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2507 - metric/ndcg_1: 0.3923 - metric/ndcg_3: 0.4421 - metric/ndcg_5: 0.4735 - metric/ndcg_10: 0.5286 - val_loss: 4.8242 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5395 - val_metric/ndcg_5: 0.5343 - val_metric/ndcg_10: 0.5730\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 4.2449 - metric/ndcg_1: 0.3944 - metric/ndcg_3: 0.4414 - metric/ndcg_5: 0.4728 - metric/ndcg_10: 0.5263 - val_loss: 4.8231 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5356 - val_metric/ndcg_5: 0.5355 - val_metric/ndcg_10: 0.5764\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2542 - metric/ndcg_1: 0.3933 - metric/ndcg_3: 0.4428 - metric/ndcg_5: 0.4748 - metric/ndcg_10: 0.5274 - val_loss: 4.8203 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5391 - val_metric/ndcg_5: 0.5340 - val_metric/ndcg_10: 0.5711\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2606 - metric/ndcg_1: 0.3856 - metric/ndcg_3: 0.4382 - metric/ndcg_5: 0.4708 - metric/ndcg_10: 0.5248 - val_loss: 4.8217 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5393 - val_metric/ndcg_5: 0.5309 - val_metric/ndcg_10: 0.5727\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2665 - metric/ndcg_1: 0.3895 - metric/ndcg_3: 0.4406 - metric/ndcg_5: 0.4715 - metric/ndcg_10: 0.5256 - val_loss: 4.8250 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5340 - val_metric/ndcg_5: 0.5305 - val_metric/ndcg_10: 0.5781\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2598 - metric/ndcg_1: 0.3903 - metric/ndcg_3: 0.4402 - metric/ndcg_5: 0.4732 - metric/ndcg_10: 0.5262 - val_loss: 4.8204 - val_metric/ndcg_1: 0.4973 - val_metric/ndcg_3: 0.5413 - val_metric/ndcg_5: 0.5368 - val_metric/ndcg_10: 0.5760\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2545 - metric/ndcg_1: 0.3929 - metric/ndcg_3: 0.4407 - metric/ndcg_5: 0.4732 - metric/ndcg_10: 0.5267 - val_loss: 4.8197 - val_metric/ndcg_1: 0.4997 - val_metric/ndcg_3: 0.5384 - val_metric/ndcg_5: 0.5356 - val_metric/ndcg_10: 0.5722\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2577 - metric/ndcg_1: 0.3963 - metric/ndcg_3: 0.4421 - metric/ndcg_5: 0.4735 - metric/ndcg_10: 0.5253 - val_loss: 4.8209 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5398 - val_metric/ndcg_5: 0.5349 - val_metric/ndcg_10: 0.5736\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 4.2384 - metric/ndcg_1: 0.3960 - metric/ndcg_3: 0.4460 - metric/ndcg_5: 0.4763 - metric/ndcg_10: 0.5276 - val_loss: 4.8228 - val_metric/ndcg_1: 0.4955 - val_metric/ndcg_3: 0.5345 - val_metric/ndcg_5: 0.5408 - val_metric/ndcg_10: 0.5737\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 4.2493 - metric/ndcg_1: 0.3888 - metric/ndcg_3: 0.4456 - metric/ndcg_5: 0.4740 - metric/ndcg_10: 0.5260 - val_loss: 4.8208 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5398 - val_metric/ndcg_5: 0.5350 - val_metric/ndcg_10: 0.5736\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2591 - metric/ndcg_1: 0.3972 - metric/ndcg_3: 0.4448 - metric/ndcg_5: 0.4741 - metric/ndcg_10: 0.5283 - val_loss: 4.8202 - val_metric/ndcg_1: 0.5298 - val_metric/ndcg_3: 0.5472 - val_metric/ndcg_5: 0.5401 - val_metric/ndcg_10: 0.5795\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2651 - metric/ndcg_1: 0.3923 - metric/ndcg_3: 0.4405 - metric/ndcg_5: 0.4725 - metric/ndcg_10: 0.5261 - val_loss: 4.8230 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5383 - val_metric/ndcg_5: 0.5308 - val_metric/ndcg_10: 0.5787\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2550 - metric/ndcg_1: 0.3954 - metric/ndcg_3: 0.4426 - metric/ndcg_5: 0.4749 - metric/ndcg_10: 0.5276 - val_loss: 4.8202 - val_metric/ndcg_1: 0.5225 - val_metric/ndcg_3: 0.5453 - val_metric/ndcg_5: 0.5397 - val_metric/ndcg_10: 0.5832\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2569 - metric/ndcg_1: 0.3942 - metric/ndcg_3: 0.4443 - metric/ndcg_5: 0.4735 - metric/ndcg_10: 0.5265 - val_loss: 4.8201 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5421 - val_metric/ndcg_5: 0.5345 - val_metric/ndcg_10: 0.5714\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2646 - metric/ndcg_1: 0.3932 - metric/ndcg_3: 0.4435 - metric/ndcg_5: 0.4747 - metric/ndcg_10: 0.5262 - val_loss: 4.8211 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5444 - val_metric/ndcg_5: 0.5368 - val_metric/ndcg_10: 0.5765\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2443 - metric/ndcg_1: 0.3865 - metric/ndcg_3: 0.4417 - metric/ndcg_5: 0.4751 - metric/ndcg_10: 0.5277 - val_loss: 4.8259 - val_metric/ndcg_1: 0.5004 - val_metric/ndcg_3: 0.5331 - val_metric/ndcg_5: 0.5294 - val_metric/ndcg_10: 0.5752\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 4.2428 - metric/ndcg_1: 0.3936 - metric/ndcg_3: 0.4431 - metric/ndcg_5: 0.4753 - metric/ndcg_10: 0.5274 - val_loss: 4.8213 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5322 - val_metric/ndcg_5: 0.5309 - val_metric/ndcg_10: 0.5755\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 4.2572 - metric/ndcg_1: 0.3944 - metric/ndcg_3: 0.4399 - metric/ndcg_5: 0.4731 - metric/ndcg_10: 0.5277 - val_loss: 4.8199 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5397 - val_metric/ndcg_5: 0.5347 - val_metric/ndcg_10: 0.5709\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 4.2678 - metric/ndcg_1: 0.3879 - metric/ndcg_3: 0.4403 - metric/ndcg_5: 0.4730 - metric/ndcg_10: 0.5249 - val_loss: 4.8222 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5353 - val_metric/ndcg_5: 0.5335 - val_metric/ndcg_10: 0.5739\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 4.2564 - metric/ndcg_1: 0.3917 - metric/ndcg_3: 0.4429 - metric/ndcg_5: 0.4751 - metric/ndcg_10: 0.5259 - val_loss: 4.8238 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5379 - val_metric/ndcg_5: 0.5343 - val_metric/ndcg_10: 0.5744\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 4.2669 - metric/ndcg_1: 0.3976 - metric/ndcg_3: 0.4454 - metric/ndcg_5: 0.4774 - metric/ndcg_10: 0.5302 - val_loss: 4.8205 - val_metric/ndcg_1: 0.4720 - val_metric/ndcg_3: 0.5329 - val_metric/ndcg_5: 0.5285 - val_metric/ndcg_10: 0.5695\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2524 - metric/ndcg_1: 0.3937 - metric/ndcg_3: 0.4397 - metric/ndcg_5: 0.4741 - metric/ndcg_10: 0.5262 - val_loss: 4.8199 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5391 - val_metric/ndcg_5: 0.5362 - val_metric/ndcg_10: 0.5710\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2525 - metric/ndcg_1: 0.3873 - metric/ndcg_3: 0.4403 - metric/ndcg_5: 0.4708 - metric/ndcg_10: 0.5249 - val_loss: 4.8216 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5437 - val_metric/ndcg_5: 0.5359 - val_metric/ndcg_10: 0.5733\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2415 - metric/ndcg_1: 0.3962 - metric/ndcg_3: 0.4395 - metric/ndcg_5: 0.4715 - metric/ndcg_10: 0.5248 - val_loss: 4.8232 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5356 - val_metric/ndcg_5: 0.5299 - val_metric/ndcg_10: 0.5736\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2535 - metric/ndcg_1: 0.3915 - metric/ndcg_3: 0.4444 - metric/ndcg_5: 0.4759 - metric/ndcg_10: 0.5277 - val_loss: 4.8212 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5373 - val_metric/ndcg_5: 0.5331 - val_metric/ndcg_10: 0.5705\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2603 - metric/ndcg_1: 0.3910 - metric/ndcg_3: 0.4428 - metric/ndcg_5: 0.4752 - metric/ndcg_10: 0.5286 - val_loss: 4.8210 - val_metric/ndcg_1: 0.4997 - val_metric/ndcg_3: 0.5388 - val_metric/ndcg_5: 0.5321 - val_metric/ndcg_10: 0.5688\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2673 - metric/ndcg_1: 0.3861 - metric/ndcg_3: 0.4376 - metric/ndcg_5: 0.4702 - metric/ndcg_10: 0.5248 - val_loss: 4.8249 - val_metric/ndcg_1: 0.5077 - val_metric/ndcg_3: 0.5328 - val_metric/ndcg_5: 0.5279 - val_metric/ndcg_10: 0.5745\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2568 - metric/ndcg_1: 0.3888 - metric/ndcg_3: 0.4404 - metric/ndcg_5: 0.4731 - metric/ndcg_10: 0.5265 - val_loss: 4.8201 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5393 - val_metric/ndcg_5: 0.5332 - val_metric/ndcg_10: 0.5689\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2570 - metric/ndcg_1: 0.3914 - metric/ndcg_3: 0.4433 - metric/ndcg_5: 0.4759 - metric/ndcg_10: 0.5287 - val_loss: 4.8199 - val_metric/ndcg_1: 0.4997 - val_metric/ndcg_3: 0.5356 - val_metric/ndcg_5: 0.5292 - val_metric/ndcg_10: 0.5685\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2612 - metric/ndcg_1: 0.3921 - metric/ndcg_3: 0.4419 - metric/ndcg_5: 0.4751 - metric/ndcg_10: 0.5260 - val_loss: 4.8226 - val_metric/ndcg_1: 0.4720 - val_metric/ndcg_3: 0.5376 - val_metric/ndcg_5: 0.5309 - val_metric/ndcg_10: 0.5712\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2374 - metric/ndcg_1: 0.3935 - metric/ndcg_3: 0.4456 - metric/ndcg_5: 0.4771 - metric/ndcg_10: 0.5284 - val_loss: 4.8243 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5361 - val_metric/ndcg_5: 0.5354 - val_metric/ndcg_10: 0.5735\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 4.2478 - metric/ndcg_1: 0.3892 - metric/ndcg_3: 0.4380 - metric/ndcg_5: 0.4723 - metric/ndcg_10: 0.5259 - val_loss: 4.8204 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5398 - val_metric/ndcg_5: 0.5356 - val_metric/ndcg_10: 0.5786\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2564 - metric/ndcg_1: 0.3991 - metric/ndcg_3: 0.4470 - metric/ndcg_5: 0.4799 - metric/ndcg_10: 0.5306 - val_loss: 4.8199 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5391 - val_metric/ndcg_5: 0.5334 - val_metric/ndcg_10: 0.5719\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2652 - metric/ndcg_1: 0.3946 - metric/ndcg_3: 0.4435 - metric/ndcg_5: 0.4735 - metric/ndcg_10: 0.5265 - val_loss: 4.8220 - val_metric/ndcg_1: 0.4997 - val_metric/ndcg_3: 0.5331 - val_metric/ndcg_5: 0.5279 - val_metric/ndcg_10: 0.5714\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2622 - metric/ndcg_1: 0.3911 - metric/ndcg_3: 0.4433 - metric/ndcg_5: 0.4727 - metric/ndcg_10: 0.5260 - val_loss: 4.8203 - val_metric/ndcg_1: 0.4923 - val_metric/ndcg_3: 0.5313 - val_metric/ndcg_5: 0.5278 - val_metric/ndcg_10: 0.5752\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2603 - metric/ndcg_1: 0.3888 - metric/ndcg_3: 0.4396 - metric/ndcg_5: 0.4727 - metric/ndcg_10: 0.5261 - val_loss: 4.8194 - val_metric/ndcg_1: 0.4923 - val_metric/ndcg_3: 0.5378 - val_metric/ndcg_5: 0.5312 - val_metric/ndcg_10: 0.5764\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2577 - metric/ndcg_1: 0.3965 - metric/ndcg_3: 0.4410 - metric/ndcg_5: 0.4747 - metric/ndcg_10: 0.5261 - val_loss: 4.8200 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5407 - val_metric/ndcg_5: 0.5353 - val_metric/ndcg_10: 0.5764\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2439 - metric/ndcg_1: 0.3953 - metric/ndcg_3: 0.4454 - metric/ndcg_5: 0.4777 - metric/ndcg_10: 0.5297 - val_loss: 4.8239 - val_metric/ndcg_1: 0.4955 - val_metric/ndcg_3: 0.5320 - val_metric/ndcg_5: 0.5288 - val_metric/ndcg_10: 0.5727\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2426 - metric/ndcg_1: 0.3899 - metric/ndcg_3: 0.4389 - metric/ndcg_5: 0.4721 - metric/ndcg_10: 0.5261 - val_loss: 4.8227 - val_metric/ndcg_1: 0.5004 - val_metric/ndcg_3: 0.5324 - val_metric/ndcg_5: 0.5366 - val_metric/ndcg_10: 0.5761\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2547 - metric/ndcg_1: 0.3947 - metric/ndcg_3: 0.4485 - metric/ndcg_5: 0.4773 - metric/ndcg_10: 0.5297 - val_loss: 4.8194 - val_metric/ndcg_1: 0.4997 - val_metric/ndcg_3: 0.5408 - val_metric/ndcg_5: 0.5350 - val_metric/ndcg_10: 0.5715\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2668 - metric/ndcg_1: 0.3895 - metric/ndcg_3: 0.4413 - metric/ndcg_5: 0.4732 - metric/ndcg_10: 0.5266 - val_loss: 4.8206 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5372 - val_metric/ndcg_5: 0.5352 - val_metric/ndcg_10: 0.5770\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2593 - metric/ndcg_1: 0.3943 - metric/ndcg_3: 0.4452 - metric/ndcg_5: 0.4753 - metric/ndcg_10: 0.5287 - val_loss: 4.8229 - val_metric/ndcg_1: 0.4955 - val_metric/ndcg_3: 0.5293 - val_metric/ndcg_5: 0.5277 - val_metric/ndcg_10: 0.5739\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 4.2652 - metric/ndcg_1: 0.3888 - metric/ndcg_3: 0.4396 - metric/ndcg_5: 0.4726 - metric/ndcg_10: 0.5266 - val_loss: 4.8197 - val_metric/ndcg_1: 0.4720 - val_metric/ndcg_3: 0.5304 - val_metric/ndcg_5: 0.5263 - val_metric/ndcg_10: 0.5661\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2501 - metric/ndcg_1: 0.4002 - metric/ndcg_3: 0.4444 - metric/ndcg_5: 0.4751 - metric/ndcg_10: 0.5285 - val_loss: 4.8194 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5389 - val_metric/ndcg_5: 0.5363 - val_metric/ndcg_10: 0.5719\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 4.2596 - metric/ndcg_1: 0.3917 - metric/ndcg_3: 0.4423 - metric/ndcg_5: 0.4732 - metric/ndcg_10: 0.5272 - val_loss: 4.8214 - val_metric/ndcg_1: 0.4955 - val_metric/ndcg_3: 0.5392 - val_metric/ndcg_5: 0.5336 - val_metric/ndcg_10: 0.5728\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2369 - metric/ndcg_1: 0.4016 - metric/ndcg_3: 0.4457 - metric/ndcg_5: 0.4767 - metric/ndcg_10: 0.5280 - val_loss: 4.8230 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5311 - val_metric/ndcg_5: 0.5296 - val_metric/ndcg_10: 0.5760\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2536 - metric/ndcg_1: 0.3883 - metric/ndcg_3: 0.4419 - metric/ndcg_5: 0.4723 - metric/ndcg_10: 0.5253 - val_loss: 4.8201 - val_metric/ndcg_1: 0.4955 - val_metric/ndcg_3: 0.5370 - val_metric/ndcg_5: 0.5329 - val_metric/ndcg_10: 0.5741\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2588 - metric/ndcg_1: 0.3977 - metric/ndcg_3: 0.4458 - metric/ndcg_5: 0.4771 - metric/ndcg_10: 0.5289 - val_loss: 4.8198 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5371 - val_metric/ndcg_5: 0.5312 - val_metric/ndcg_10: 0.5704\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2652 - metric/ndcg_1: 0.3922 - metric/ndcg_3: 0.4459 - metric/ndcg_5: 0.4767 - metric/ndcg_10: 0.5289 - val_loss: 4.8235 - val_metric/ndcg_1: 0.5004 - val_metric/ndcg_3: 0.5303 - val_metric/ndcg_5: 0.5257 - val_metric/ndcg_10: 0.5743\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2557 - metric/ndcg_1: 0.3928 - metric/ndcg_3: 0.4426 - metric/ndcg_5: 0.4728 - metric/ndcg_10: 0.5266 - val_loss: 4.8205 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5379 - val_metric/ndcg_5: 0.5324 - val_metric/ndcg_10: 0.5702\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 4.2576 - metric/ndcg_1: 0.3979 - metric/ndcg_3: 0.4447 - metric/ndcg_5: 0.4772 - metric/ndcg_10: 0.5286 - val_loss: 4.8196 - val_metric/ndcg_1: 0.4997 - val_metric/ndcg_3: 0.5381 - val_metric/ndcg_5: 0.5341 - val_metric/ndcg_10: 0.5706\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2600 - metric/ndcg_1: 0.3825 - metric/ndcg_3: 0.4389 - metric/ndcg_5: 0.4718 - metric/ndcg_10: 0.5249 - val_loss: 4.8215 - val_metric/ndcg_1: 0.5029 - val_metric/ndcg_3: 0.5407 - val_metric/ndcg_5: 0.5320 - val_metric/ndcg_10: 0.5730\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2414 - metric/ndcg_1: 0.3925 - metric/ndcg_3: 0.4407 - metric/ndcg_5: 0.4748 - metric/ndcg_10: 0.5271 - val_loss: 4.8229 - val_metric/ndcg_1: 0.4955 - val_metric/ndcg_3: 0.5230 - val_metric/ndcg_5: 0.5303 - val_metric/ndcg_10: 0.5749\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2456 - metric/ndcg_1: 0.3945 - metric/ndcg_3: 0.4444 - metric/ndcg_5: 0.4754 - metric/ndcg_10: 0.5262 - val_loss: 4.8202 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5431 - val_metric/ndcg_5: 0.5323 - val_metric/ndcg_10: 0.5758\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 4.2586 - metric/ndcg_1: 0.3996 - metric/ndcg_3: 0.4453 - metric/ndcg_5: 0.4776 - metric/ndcg_10: 0.5290 - val_loss: 4.8201 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5389 - val_metric/ndcg_5: 0.5319 - val_metric/ndcg_10: 0.5688\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 4.2601 - metric/ndcg_1: 0.3974 - metric/ndcg_3: 0.4460 - metric/ndcg_5: 0.4762 - metric/ndcg_10: 0.5289 - val_loss: 4.8211 - val_metric/ndcg_1: 0.5045 - val_metric/ndcg_3: 0.5340 - val_metric/ndcg_5: 0.5299 - val_metric/ndcg_10: 0.5722\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2651 - metric/ndcg_1: 0.3958 - metric/ndcg_3: 0.4445 - metric/ndcg_5: 0.4774 - metric/ndcg_10: 0.5282 - val_loss: 4.8202 - val_metric/ndcg_1: 0.4971 - val_metric/ndcg_3: 0.5322 - val_metric/ndcg_5: 0.5314 - val_metric/ndcg_10: 0.5736\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.2606 - metric/ndcg_1: 0.3952 - metric/ndcg_3: 0.4449 - metric/ndcg_5: 0.4764 - metric/ndcg_10: 0.5284 - val_loss: 4.8196 - val_metric/ndcg_1: 0.4997 - val_metric/ndcg_3: 0.5408 - val_metric/ndcg_5: 0.5351 - val_metric/ndcg_10: 0.5700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f05d4eb070>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(_MODEL_DIR)\n",
    "\n",
    "ranker.fit(train_dataset,\n",
    "           validation_data=vali_dataset,\n",
    "           steps_per_epoch=100,\n",
    "           epochs=100,\n",
    "           validation_steps=1,\n",
    "           callbacks=[tensorboard_callback],\n",
    "           verbose='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53141e0b-acee-4873-937c-416bcab5418a",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e608c-296b-4efc-bffc-88deaeeecdfe",
   "metadata": {},
   "source": [
    "#### TensorBoard for Train & Eval tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ef6880cc-166a-4325-882f-53484e584157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 27076), started 1 day, 13:55:20 ago. (Use '!kill 27076' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-794b387f6dffec66\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-794b387f6dffec66\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./Models #--port 25952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cea062ba-8c24-4275-ac48-33b50477b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The tensorboard extension is already loaded. To reload it, use:\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741d25d-1610-47de-9030-db3758f3bfcd",
   "metadata": {},
   "source": [
    "### Testing the ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f45549-287b-4693-b69e-f55f0d1fe8e6",
   "metadata": {},
   "source": [
    "The model returns as predictions an array of size (num_queries,list_size), where each row contains the scores of each document in the same order they were inputted by the data pipeline (note that if the num_docs < list_size, the scores of the last docs are dummy docs that were padded).\n",
    "I order to associate each score with the correct doc (company), we will parse the TFRecords, and obtain the list of companies for each query (date), in the same order that were inputted to the predict() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "c7c0a1ce-9ca0-4967-9fd2-58f29c3226ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's parse the TFRecords in order to obtain the id of each query + the list of ids of the documents in each query\n",
    "raw_dataset = tf.data.TFRecordDataset([_VALID_DATA_PATH])\n",
    "\n",
    "query_docs_list = [] #A list that will be populated with tuples (query_id, list_of_docs)\n",
    "for raw_record in raw_dataset.take(-1): #take(-1) takes all the records in raw_dataset\n",
    "    ELWC = input_pb2.ExampleListWithContext()\n",
    "    v = ELWC.FromString(raw_record.numpy()) #v is composed by v.context and a set of examples in v.examples\n",
    "    \n",
    "    query_id = v.context.features.feature['qid'].bytes_list.value[0].decode('UTF-8')\n",
    "    docs_list = []\n",
    "    for e in v.examples:\n",
    "        doc_id = e.features.feature['doc'].bytes_list.value[0].decode('UTF-8')\n",
    "        docs_list.append(doc_id)\n",
    "        \n",
    "    query_docs_list.append((query_id, docs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "b326bda5-4474-404d-9870-668b60c78c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ranker.predict(vali_dataset,\n",
    "                             batch_size=None,\n",
    "                             verbose='auto',\n",
    "                             steps=None,\n",
    "                             callbacks=None)\n",
    "\n",
    "predictions_record = [] #List that will contain  the prediction tuples (date, ranking_of_companies)\n",
    "queries = []\n",
    "docs_per_query = []\n",
    "for idx, query_docs in enumerate(query_docs_list):\n",
    "    query, docs = query_docs\n",
    "    scores = list(predictions[idx])\n",
    "    dict_doc_scr = dict(zip(docs, scores))\n",
    "    sorted_dict = dict(sorted(dict_doc_scr.items(), key=lambda item: item[1], reverse=True))\n",
    "    queries.append(query)\n",
    "    docs_per_query.append(list(sorted_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "90e8c299-1c25-40ea-be29-6af14166caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'date': queries, 'ranking': docs_per_query}\n",
    "\n",
    "df = pd.DataFrame.from_dict(result_dict, orient='index')\n",
    "df = df.transpose()\n",
    "df.to_csv('ranking_results.csv', index=False, header=True,  encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
