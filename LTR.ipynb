{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78d4e0-4f6d-4402-944d-b45d1cd41cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df59358-c241-47ed-ac1b-08fa5a5798ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q tensorflow_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882de103-0423-443b-ba22-51ce6984eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "PATH = os.getcwd()\n",
    "#PATH = '/content/drive/Shareddrives/Master Tesis/Tesis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6fca1fd-c334-453b-987f-e17862bb101f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>big_log_ret</th>\n",
       "      <th>big_RCV</th>\n",
       "      <th>big_RVT</th>\n",
       "      <th>big_positivePartscr</th>\n",
       "      <th>big_negativePartscr</th>\n",
       "      <th>big_splogscr</th>\n",
       "      <th>big_linscr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AAL</td>\n",
       "      <td>0.063980</td>\n",
       "      <td>8.476000</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>54.733580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.006151</td>\n",
       "      <td>13.162167</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.015650</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>48.380133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-0.020684</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>65.547120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>ABT</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>-24.607200</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>-0.012980</td>\n",
       "      <td>27.375300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>-3.370000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.024640</td>\n",
       "      <td>40.688020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41819</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>UPS</td>\n",
       "      <td>-0.022512</td>\n",
       "      <td>-42.160333</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>-0.008817</td>\n",
       "      <td>46.677617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41820</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>USB</td>\n",
       "      <td>-0.033782</td>\n",
       "      <td>-28.514833</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.037033</td>\n",
       "      <td>68.229333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41821</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>VZ</td>\n",
       "      <td>-0.007363</td>\n",
       "      <td>-22.016000</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>0.036629</td>\n",
       "      <td>-0.066443</td>\n",
       "      <td>28.958114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41822</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>WFC</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-37.779000</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>-0.061550</td>\n",
       "      <td>15.077883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41823</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>WMT</td>\n",
       "      <td>-0.052347</td>\n",
       "      <td>-12.486143</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.020143</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>-0.029786</td>\n",
       "      <td>50.108929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41824 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Query Ticker  big_log_ret    big_RCV   big_RVT  \\\n",
       "0      2012-01-08    AAL     0.063980   8.476000  0.000280   \n",
       "1      2012-01-08   AAPL    -0.006151  13.162167  0.003400   \n",
       "2      2012-01-08    ABC    -0.020684   0.404000  0.000760   \n",
       "3      2012-01-08    ABT     0.000863 -24.607200  0.000320   \n",
       "4      2012-01-08   AMZN    -0.023212  -3.370000  0.001100   \n",
       "...           ...    ...          ...        ...       ...   \n",
       "41819  2021-11-28    UPS    -0.022512 -42.160333  0.000317   \n",
       "41820  2021-11-28    USB    -0.033782 -28.514833  0.000483   \n",
       "41821  2021-11-28     VZ    -0.007363 -22.016000  0.000686   \n",
       "41822  2021-11-28    WFC    -0.014140 -37.779000  0.000983   \n",
       "41823  2021-11-28    WMT    -0.052347 -12.486143  0.000643   \n",
       "\n",
       "       big_positivePartscr  big_negativePartscr  big_splogscr  big_linscr  \n",
       "0                 0.020240             0.013340      0.010760   54.733580  \n",
       "1                 0.016050             0.015650      0.020333   48.380133  \n",
       "2                 0.027820             0.012980      0.017000   65.547120  \n",
       "3                 0.010820             0.018540     -0.012980   27.375300  \n",
       "4                 0.016180             0.020000     -0.024640   40.688020  \n",
       "...                    ...                  ...           ...         ...  \n",
       "41819             0.018200             0.024717     -0.008817   46.677617  \n",
       "41820             0.020517             0.010367      0.037033   68.229333  \n",
       "41821             0.018957             0.036629     -0.066443   28.958114  \n",
       "41822             0.004283             0.017333     -0.061550   15.077883  \n",
       "41823             0.020143             0.027329     -0.029786   50.108929  \n",
       "\n",
       "[41824 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_ranking as tfr\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import input_pb2\n",
    "\n",
    "final_table = pd.read_csv(os.path.join(PATH, 'Tables', 'final_table.csv'))\n",
    "final_table['Query'] = pd.to_datetime(final_table['Query']).dt.date\n",
    "final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b993f-93d3-42da-80a4-6e68cc411227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the paths to files containing training and test instances.\n",
    "_TRAIN_DATA_PATH = \"./Dataset-tfrecords/Split_1/train.tfrecord\"\n",
    "#_TEST_DATA_PATH =  f\"{dataset_folder_path}/test-fold1.gzip_tfrecord\"\n",
    "\n",
    "# The maximum number of documents per query in the dataset.\n",
    "# Document lists are padded or truncated to this size.\n",
    "_LIST_SIZE = 200\n",
    "\n",
    "# The document relevance label.\n",
    "_LABEL_FEATURE_NAME = \"rel\"\n",
    "_NUM_FEATURES = final_table.shape[1] -3\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "\n",
    "# Learning rate for optimizer.\n",
    "_LEARNING_RATE = 0.05\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 32\n",
    "_DROPOUT_RATE = 0.5\n",
    "\n",
    "# Location of model directory and number of training steps.\n",
    "_MODEL_DIR = f\"./model_logs/model_{datetime.datetime.now().strftime('%m-%d-%Y_%H-%M-%S')}\"\n",
    "\n",
    "# setting as shell env for tensorboard stuff\n",
    "os.environ[\"models_dir\"] = _MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8af44-669f-4118-83a5-0f689c50cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_columns():\n",
    "    # We dont have context features in our datasets\n",
    "    context_feature_columns = {}\n",
    "    feature_names = [\"{}\".format(i + 1) for i in range(_NUM_FEATURES)]\n",
    "    example_feature_columns = {\n",
    "        name:\n",
    "        tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n",
    "        for name in feature_names}\n",
    "    \n",
    "    return context_feature_columns, example_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45798f32-6062-48c5-9958-3e7429a1ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_tfrecords(input_path:str,\n",
    "                                  batch_sz:int,\n",
    "                                  shuffle:bool = True,\n",
    "                                  num_epochs:int = None,\n",
    "                                  data_format:str = \"ELWC\",\n",
    "                                  compression_type:str = ''):\n",
    "\n",
    "    context_feature_columns, example_feature_columns = create_feature_columns()\n",
    "\n",
    "\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "      context_feature_columns.values())\n",
    "    label_column = tf.feature_column.numeric_column(\n",
    "      _LABEL_FEATURE_NAME, dtype=tf.int64, default_value=_PADDING_LABEL)\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "      list(example_feature_columns.values()) + [label_column])\n",
    "\n",
    "    _reader_arg_list = []\n",
    "    if compression_type:\n",
    "        assert compression_type in [\"\", \"GZIP\",\"ZLIB\"]\n",
    "        _reader_arg_list = [compression_type]\n",
    "\n",
    "\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "      file_pattern=input_path,\n",
    "      data_format=tfr.data.ELWC,\n",
    "      batch_size=batch_sz,\n",
    "      list_size=_LIST_SIZE,\n",
    "      context_feature_spec=context_feature_spec,\n",
    "      example_feature_spec=example_feature_spec,\n",
    "      reader=tf.data.TFRecordDataset,\n",
    "      reader_args= _reader_arg_list,\n",
    "      shuffle=shuffle,\n",
    "      num_epochs=num_epochs,\n",
    "      )\n",
    "\n",
    "    def _log1p_transform(features):\n",
    "        '''\n",
    "        computes elementwise log_e(|x|)*sign(x)\n",
    "        '''\n",
    "    transformed_feats = {\n",
    "        f:tf.math.multiply(\n",
    "            tf.math.log1p(\n",
    "                tf.math.abs(features[f])\n",
    "                ),\n",
    "            tf.math.sign(features[f])\n",
    "            )\n",
    "        for f in features}\n",
    "    return transformed_feats\n",
    "\n",
    "    def _split_label_and_transform_features(features):\n",
    "        label = tf.squeeze(features.pop(_LABEL_FEATURE_NAME), axis=2)\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        features = _log1p_transform(features)\n",
    "\n",
    "    return features, label\n",
    "\n",
    "    dataset = dataset.map(_split_label_and_transform_features)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c2f77-f0a5-4724-a2c5-d7e9a6ad6566",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feature_columns, example_feature_columns = create_feature_columns()\n",
    "# Using a Canned Network\n",
    "ranking_network = tfr.keras.canned.DNNRankingNetwork(\n",
    "      context_feature_columns=context_feature_columns,\n",
    "      example_feature_columns=example_feature_columns,\n",
    "      hidden_layer_dims=[64, 32, 16],\n",
    "      activation=tf.nn.relu,\n",
    "      dropout=_DROPOUT_RATE,\n",
    "      use_batch_norm=True,\n",
    "      batch_norm_moment=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c95200-de85-4caa-9313-2a83692ef446",
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss_obj = tfr.keras.losses.get(\n",
    "    tfr.losses.RankingLossKey.GUMBEL_APPROX_NDCG_LOSS)\n",
    "\n",
    "\n",
    "#Different Losses knowing that the softmax loss is representative of the listwise apporach\n",
    "#_loss_obj = tfr.keras.losses.get(\n",
    "#    tfr.losses.RankingLossKey.UNIQUE_SOFTMAX_LOSS)\n",
    "\n",
    "\n",
    "#_loss_obj = tfr.keras.losses.get(\n",
    "#    tfr.losses.RankingLossKey.LIST_MLE_LOSS)\n",
    "\n",
    "\n",
    "#_loss_obj = tfr.keras.losses.get(\n",
    "#    tfr.losses.RankingLossKey.SOFTMAX_LOSS)\n",
    "# Contains all ranking metrics, including NDCG @ {1, 3, 5, 10}.\n",
    "\n",
    "def _make_eval_metric_fns():\n",
    "  \"\"\"Returns a list of ranking metrics for the keras ranker\"\"\"\n",
    "  metric_fns = [tfr.keras.metrics.get(**kwargs) \n",
    "                        for kwargs in [dict(key=\"ndcg\", topn=topn, \n",
    "                                        name=\"metric/ndcg_{}\".format(topn)) \n",
    "                                            for topn in [1, 3, 5, 10]]\n",
    "                ]\n",
    "  return metric_fns\n",
    "\n",
    "default_metrics = _make_eval_metric_fns()\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "      model_dir=_MODEL_DIR,\n",
    "      keep_checkpoint_max=10,\n",
    "      save_checkpoints_secs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86499e15-7e40-4249-bbb6-2ec3cc1a565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ranker as a Functional Keras model.\n",
    "ranker = tfr.keras.model.create_keras_model(\n",
    "      network=ranking_network,\n",
    "      loss=_loss_obj,\n",
    "      metrics=default_metrics,\n",
    "      optimizer=tf.keras.optimizers.Adagrad(learning_rate=_LEARNING_RATE),\n",
    "      size_feature_name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea6108-746d-499a-8f63-6aaead1b0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.test.gpu_device_name() != '', \"GPU not detected, training is much faster GPU/TPU instance of colab\"\n",
    "\n",
    "train_dataset = create_dataset_from_tfrecords(_TRAIN_DATA_PATH,\n",
    "                                              _BATCH_SIZE,\n",
    "                                              compression_type=\"GZIP\")\n",
    "\n",
    "vali_dataset = create_dataset_from_tfrecords(_VALID_DATA_PATH,\n",
    "                                             _BATCH_SIZE,\n",
    "                                             shuffle=False,\n",
    "                                             num_epochs=1, \n",
    "                                             compression_type=\"GZIP\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(_MODEL_DIR)\n",
    "\n",
    "\n",
    "ranker.fit(train_dataset,\n",
    "           validation_data=vali_dataset,\n",
    "           steps_per_epoch=100,\n",
    "           epochs=100,\n",
    "           validation_steps=1,\n",
    "           callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402cb38-a78f-439e-9442-fbf5a3bc84ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
