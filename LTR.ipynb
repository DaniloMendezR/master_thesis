{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78d4e0-4f6d-4402-944d-b45d1cd41cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df59358-c241-47ed-ac1b-08fa5a5798ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q tensorflow_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "882de103-0423-443b-ba22-51ce6984eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "PATH = os.getcwd()\n",
    "#PATH = '/content/drive/Shareddrives/Master Tesis/Tesis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f6fca1fd-c334-453b-987f-e17862bb101f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>big_log_ret</th>\n",
       "      <th>big_RCV</th>\n",
       "      <th>big_RVT</th>\n",
       "      <th>big_positivePartscr</th>\n",
       "      <th>big_negativePartscr</th>\n",
       "      <th>big_splogscr</th>\n",
       "      <th>big_linscr</th>\n",
       "      <th>big_lag1_log_ret</th>\n",
       "      <th>big_lag4_log_ret</th>\n",
       "      <th>big_lag1_month_log_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AAL</td>\n",
       "      <td>0.063980</td>\n",
       "      <td>8.476000</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>54.733580</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>0.094986</td>\n",
       "      <td>-0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.006150</td>\n",
       "      <td>13.162167</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.015650</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>48.380133</td>\n",
       "      <td>0.042066</td>\n",
       "      <td>-0.032534</td>\n",
       "      <td>0.070567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-0.020683</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>65.547120</td>\n",
       "      <td>0.036953</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.059249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>ABT</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>-24.607200</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>-0.012980</td>\n",
       "      <td>27.375300</td>\n",
       "      <td>-0.006602</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.023364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-08</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>-3.370000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.024640</td>\n",
       "      <td>40.688020</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>-0.062913</td>\n",
       "      <td>-0.055493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42050</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>UPS</td>\n",
       "      <td>-0.022512</td>\n",
       "      <td>-42.160333</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>-0.008817</td>\n",
       "      <td>46.677617</td>\n",
       "      <td>-0.015323</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>-0.034095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42051</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>USB</td>\n",
       "      <td>-0.033782</td>\n",
       "      <td>-28.514833</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.037033</td>\n",
       "      <td>68.229333</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>-0.048707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42052</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>VZ</td>\n",
       "      <td>-0.007363</td>\n",
       "      <td>-22.016000</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>0.036629</td>\n",
       "      <td>-0.066443</td>\n",
       "      <td>28.958114</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>-0.014255</td>\n",
       "      <td>-0.022713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42053</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>WFC</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-37.779000</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>-0.061550</td>\n",
       "      <td>15.077883</td>\n",
       "      <td>-0.008021</td>\n",
       "      <td>-0.010320</td>\n",
       "      <td>-0.050985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42054</th>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>WMT</td>\n",
       "      <td>-0.052347</td>\n",
       "      <td>-12.486143</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.020143</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>-0.029786</td>\n",
       "      <td>50.108929</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>-0.030717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42055 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Query Ticker  big_log_ret    big_RCV   big_RVT  \\\n",
       "0      2012-01-08    AAL     0.063980   8.476000  0.000280   \n",
       "1      2012-01-08   AAPL    -0.006150  13.162167  0.003400   \n",
       "2      2012-01-08    ABC    -0.020683   0.404000  0.000760   \n",
       "3      2012-01-08    ABT     0.000864 -24.607200  0.000320   \n",
       "4      2012-01-08   AMZN    -0.023212  -3.370000  0.001100   \n",
       "...           ...    ...          ...        ...       ...   \n",
       "42050  2021-11-28    UPS    -0.022512 -42.160333  0.000317   \n",
       "42051  2021-11-28    USB    -0.033782 -28.514833  0.000483   \n",
       "42052  2021-11-28     VZ    -0.007363 -22.016000  0.000686   \n",
       "42053  2021-11-28    WFC    -0.014140 -37.779000  0.000983   \n",
       "42054  2021-11-28    WMT    -0.052347 -12.486143  0.000643   \n",
       "\n",
       "       big_positivePartscr  big_negativePartscr  big_splogscr  big_linscr  \\\n",
       "0                 0.020240             0.013340      0.010760   54.733580   \n",
       "1                 0.016050             0.015650      0.020333   48.380133   \n",
       "2                 0.027820             0.012980      0.017000   65.547120   \n",
       "3                 0.010820             0.018540     -0.012980   27.375300   \n",
       "4                 0.016180             0.020000     -0.024640   40.688020   \n",
       "...                    ...                  ...           ...         ...   \n",
       "42050             0.018200             0.024717     -0.008817   46.677617   \n",
       "42051             0.020517             0.010367      0.037033   68.229333   \n",
       "42052             0.018957             0.036629     -0.066443   28.958114   \n",
       "42053             0.004283             0.017333     -0.061550   15.077883   \n",
       "42054             0.020143             0.027329     -0.029786   50.108929   \n",
       "\n",
       "       big_lag1_log_ret  big_lag4_log_ret  big_lag1_month_log_ret  \n",
       "0              0.099426          0.094986               -0.003565  \n",
       "1              0.042066         -0.032534                0.070567  \n",
       "2              0.036953          0.010394                0.059249  \n",
       "3             -0.006602          0.005847                0.023364  \n",
       "4              0.053483         -0.062913               -0.055493  \n",
       "...                 ...               ...                     ...  \n",
       "42050         -0.015323         -0.024901               -0.034095  \n",
       "42051         -0.001564          0.005287               -0.048707  \n",
       "42052          0.018313         -0.014255               -0.022713  \n",
       "42053         -0.008021         -0.010320               -0.050985  \n",
       "42054          0.017474          0.005406               -0.030717  \n",
       "\n",
       "[42055 rows x 12 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_ranking as tfr\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import input_pb2\n",
    "\n",
    "final_table = pd.read_csv(os.path.join(PATH, 'Tables', 'final_table.csv'))\n",
    "final_table['Query'] = pd.to_datetime(final_table['Query']).dt.date\n",
    "final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8c4b993f-93d3-42da-80a4-6e68cc411227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the paths to files containing training and test instances.\n",
    "_TRAIN_DATA_PATH = \"./Dataset-tfrecords/70v30Split/train.tfrecord\"\n",
    "_VALID_DATA_PATH =  \"./Dataset-tfrecords/70v30Split/test.tfrecord\"\n",
    "\n",
    "# The maximum number of documents per query in the dataset.\n",
    "# Document lists are padded or truncated to this size.\n",
    "_LIST_SIZE = final_table.groupby(\"Query\").count().max()[0] #108 documents\n",
    "\n",
    "# The document relevance label in the tf-records.\n",
    "_LABEL_FEATURE_NAME = \"rel\"\n",
    "_NUM_FEATURES = final_table.shape[1] - 3\n",
    "_NAME_FEATURES = list(final_table.columns[3:]) #Name of the doc features (\"doc id\" and \"rel\" are not features)\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "\n",
    "# Learning rate for optimizer.\n",
    "_LEARNING_RATE = 0.05\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 32\n",
    "_DROPOUT_RATE = 0.5\n",
    "\n",
    "# Location of model directory and number of training steps.\n",
    "_MODEL_DIR = f\"./Models/model_{dt.datetime.now().strftime('%m-%d-%Y_%H-%M-%S')}\"\n",
    "\n",
    "# setting as shell env for tensorboard stuff\n",
    "os.environ[\"models_dir\"] = _MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "82d8af44-669f-4118-83a5-0f689c50cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Specifying Features via Feature Columns: (see https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html)\n",
    "\n",
    "Feature Columns are TensorFlow abstractions that are used to capture rich information about each feature.\n",
    "It allows for easy transformations for a diverse range of raw features and for interfacing with Estimators.\n",
    "\n",
    "Consistent with our input formats for ranking, such as ELWC format, we create feature columns for context features \n",
    "and example features.\n",
    "'''\n",
    "\n",
    "def create_feature_columns():\n",
    "    # We dont have context featuresin in our datasets (query id is not a feature)\n",
    "    context_feature_columns = {}\n",
    "    \n",
    "    feature_names = _NAME_FEATURES\n",
    "    example_feature_columns = {\n",
    "        name:\n",
    "        tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n",
    "        for name in feature_names}\n",
    "    \n",
    "    return context_feature_columns, example_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "45798f32-6062-48c5-9958-3e7429a1ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_tfrecords(input_path:str,\n",
    "                                  batch_sz:int,\n",
    "                                  list_sz:int,\n",
    "                                  shuffle:bool = True,\n",
    "                                  num_epochs:int = None,\n",
    "                                  data_format:str = \"ELWC\",\n",
    "                                  compression_type:str = ''):\n",
    "\n",
    "    context_feature_columns, example_feature_columns = create_feature_columns()\n",
    "\n",
    "\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "      context_feature_columns.values())\n",
    "    label_column = tf.feature_column.numeric_column(\n",
    "      _LABEL_FEATURE_NAME, dtype=tf.float32, default_value=_PADDING_LABEL)\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "      list(example_feature_columns.values()) + [label_column])\n",
    "\n",
    "    _reader_arg_list = []\n",
    "    if compression_type:\n",
    "        assert compression_type in [\"\", \"GZIP\",\"ZLIB\"]\n",
    "        _reader_arg_list = [compression_type]\n",
    "\n",
    "\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "      file_pattern=input_path,\n",
    "      data_format=tfr.data.ELWC,\n",
    "      batch_size=batch_sz,\n",
    "      list_size=list_sz,\n",
    "      context_feature_spec=context_feature_spec,\n",
    "      example_feature_spec=example_feature_spec,\n",
    "      reader=tf.data.TFRecordDataset,\n",
    "      reader_args= _reader_arg_list,\n",
    "      shuffle=shuffle,\n",
    "      num_epochs=num_epochs,\n",
    "      )\n",
    "    \n",
    "    def _log1p_transform(features):\n",
    "        '''\n",
    "        computes elementwise log_e(|x|)*sign(x)\n",
    "        '''\n",
    "        transformed_feats = {\n",
    "            f:tf.math.multiply(\n",
    "                tf.math.log1p(\n",
    "                    tf.math.abs(features[f])\n",
    "                    ),\n",
    "                tf.math.sign(features[f])\n",
    "                )\n",
    "            for f in features}\n",
    "        return transformed_feats\n",
    "\n",
    "    def _split_label_and_transform_features(features):\n",
    "        label = tf.squeeze(features.pop(_LABEL_FEATURE_NAME), axis=2)\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        features = features #_log1p_transform(features)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "    dataset = dataset.map(_split_label_and_transform_features)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5c6c2f77-f0a5-4724-a2c5-d7e9a6ad6566",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feature_columns, example_feature_columns = create_feature_columns()\n",
    "# Using a Canned Network\n",
    "ranking_network = tfr.keras.canned.DNNRankingNetwork(\n",
    "      context_feature_columns=context_feature_columns,\n",
    "      example_feature_columns=example_feature_columns,\n",
    "      hidden_layer_dims=[64, 24, 10],\n",
    "      activation=tf.nn.relu,\n",
    "      dropout=_DROPOUT_RATE,\n",
    "      use_batch_norm=True,\n",
    "      batch_norm_moment=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b2c95200-de85-4caa-9313-2a83692ef446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different Losses knowing that the softmax loss is representative of the listwise apporach\n",
    "#_loss_obj = tfr.keras.losses.get(\n",
    "#    tfr.losses.RankingLossKey.GUMBEL_APPROX_NDCG_LOSS)\n",
    "\n",
    "\n",
    "#_loss_obj = tfr.keras.losses.get(\n",
    "#    tfr.losses.RankingLossKey.UNIQUE_SOFTMAX_LOSS)\n",
    "\n",
    "\n",
    "#_loss_obj = tfr.keras.losses.get(\n",
    "#    tfr.losses.RankingLossKey.LIST_MLE_LOSS)\n",
    "\n",
    "\n",
    "_loss_obj = tfr.keras.losses.get(\n",
    "    tfr.losses.RankingLossKey.SOFTMAX_LOSS)\n",
    "# Contains all ranking metrics, including NDCG @ {1, 3, 5, 10}.\n",
    "\n",
    "def _make_eval_metric_fns():\n",
    "    \"\"\"Returns a list of ranking metrics for the keras ranker\"\"\"\n",
    "    metric_fns = [tfr.keras.metrics.get(**kwargs) \n",
    "                        for kwargs in [dict(key=\"ndcg\", topn=topn, \n",
    "                                        name=\"metric/ndcg_{}\".format(topn)) \n",
    "                                            for topn in [1, 3, 5, 10]]\n",
    "                ]\n",
    "    return metric_fns\n",
    "\n",
    "default_metrics = _make_eval_metric_fns()\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "      model_dir=_MODEL_DIR,\n",
    "      keep_checkpoint_max=10,\n",
    "      save_checkpoints_secs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "86499e15-7e40-4249-bbb6-2ec3cc1a565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ranker as a Functional Keras model.\n",
    "ranker = tfr.keras.model.create_keras_model(network=ranking_network,\n",
    "                                            loss=_loss_obj,\n",
    "                                            metrics=default_metrics,\n",
    "                                            optimizer=tf.keras.optimizers.Adagrad(learning_rate=_LEARNING_RATE),\n",
    "                                            size_feature_name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cdea6108-746d-499a-8f63-6aaead1b0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert tf.test.gpu_device_name() != '', \"GPU not detected, training is much faster GPU/TPU instance of colab\"\n",
    "\n",
    "train_dataset = create_dataset_from_tfrecords(_TRAIN_DATA_PATH,\n",
    "                                              _BATCH_SIZE,\n",
    "                                              _LIST_SIZE,\n",
    "                                              compression_type=\"\")\n",
    "\n",
    "vali_dataset = create_dataset_from_tfrecords(_VALID_DATA_PATH,\n",
    "                                             _BATCH_SIZE,\n",
    "                                             _LIST_SIZE,\n",
    "                                             shuffle=False,\n",
    "                                             num_epochs=1, \n",
    "                                             compression_type=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f80a00f3-b91a-405a-a3d6-fed0e6acfcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 3s 15ms/step - loss: 5.3742 - metric/ndcg_1: 0.2621 - metric/ndcg_3: 0.3112 - metric/ndcg_5: 0.3473 - metric/ndcg_10: 0.4109 - val_loss: 5.5724 - val_metric/ndcg_1: 0.2222 - val_metric/ndcg_3: 0.2741 - val_metric/ndcg_5: 0.3105 - val_metric/ndcg_10: 0.3709\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.2080 - metric/ndcg_1: 0.2639 - metric/ndcg_3: 0.3105 - metric/ndcg_5: 0.3445 - metric/ndcg_10: 0.4107 - val_loss: 5.5720 - val_metric/ndcg_1: 0.2562 - val_metric/ndcg_3: 0.3025 - val_metric/ndcg_5: 0.3331 - val_metric/ndcg_10: 0.3910\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2793 - metric/ndcg_1: 0.2678 - metric/ndcg_3: 0.3133 - metric/ndcg_5: 0.3472 - metric/ndcg_10: 0.4117 - val_loss: 5.5719 - val_metric/ndcg_1: 0.3033 - val_metric/ndcg_3: 0.3262 - val_metric/ndcg_5: 0.3608 - val_metric/ndcg_10: 0.4218\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.1200 - metric/ndcg_1: 0.2740 - metric/ndcg_3: 0.3168 - metric/ndcg_5: 0.3504 - metric/ndcg_10: 0.4135 - val_loss: 5.5721 - val_metric/ndcg_1: 0.2822 - val_metric/ndcg_3: 0.2813 - val_metric/ndcg_5: 0.3268 - val_metric/ndcg_10: 0.3943\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2082 - metric/ndcg_1: 0.2791 - metric/ndcg_3: 0.3180 - metric/ndcg_5: 0.3520 - metric/ndcg_10: 0.4158 - val_loss: 5.5720 - val_metric/ndcg_1: 0.2861 - val_metric/ndcg_3: 0.3004 - val_metric/ndcg_5: 0.3467 - val_metric/ndcg_10: 0.4144\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.1393 - metric/ndcg_1: 0.2734 - metric/ndcg_3: 0.3196 - metric/ndcg_5: 0.3549 - metric/ndcg_10: 0.4200 - val_loss: 5.5718 - val_metric/ndcg_1: 0.3083 - val_metric/ndcg_3: 0.3419 - val_metric/ndcg_5: 0.3850 - val_metric/ndcg_10: 0.4303\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2880 - metric/ndcg_1: 0.2755 - metric/ndcg_3: 0.3188 - metric/ndcg_5: 0.3531 - metric/ndcg_10: 0.4148 - val_loss: 5.5719 - val_metric/ndcg_1: 0.3024 - val_metric/ndcg_3: 0.3504 - val_metric/ndcg_5: 0.3759 - val_metric/ndcg_10: 0.4292\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2435 - metric/ndcg_1: 0.2758 - metric/ndcg_3: 0.3236 - metric/ndcg_5: 0.3556 - metric/ndcg_10: 0.4192 - val_loss: 5.5720 - val_metric/ndcg_1: 0.3244 - val_metric/ndcg_3: 0.3300 - val_metric/ndcg_5: 0.3775 - val_metric/ndcg_10: 0.4180\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2393 - metric/ndcg_1: 0.2794 - metric/ndcg_3: 0.3206 - metric/ndcg_5: 0.3555 - metric/ndcg_10: 0.4195 - val_loss: 5.5717 - val_metric/ndcg_1: 0.3630 - val_metric/ndcg_3: 0.3594 - val_metric/ndcg_5: 0.4026 - val_metric/ndcg_10: 0.4438\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.1798 - metric/ndcg_1: 0.2784 - metric/ndcg_3: 0.3251 - metric/ndcg_5: 0.3600 - metric/ndcg_10: 0.4235 - val_loss: 5.5717 - val_metric/ndcg_1: 0.3612 - val_metric/ndcg_3: 0.3666 - val_metric/ndcg_5: 0.4086 - val_metric/ndcg_10: 0.4424\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.1096 - metric/ndcg_1: 0.2720 - metric/ndcg_3: 0.3217 - metric/ndcg_5: 0.3551 - metric/ndcg_10: 0.4177 - val_loss: 5.5721 - val_metric/ndcg_1: 0.2918 - val_metric/ndcg_3: 0.3422 - val_metric/ndcg_5: 0.3697 - val_metric/ndcg_10: 0.4166\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2735 - metric/ndcg_1: 0.2771 - metric/ndcg_3: 0.3234 - metric/ndcg_5: 0.3568 - metric/ndcg_10: 0.4209 - val_loss: 5.5719 - val_metric/ndcg_1: 0.2786 - val_metric/ndcg_3: 0.3295 - val_metric/ndcg_5: 0.3772 - val_metric/ndcg_10: 0.4193\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2560 - metric/ndcg_1: 0.2847 - metric/ndcg_3: 0.3273 - metric/ndcg_5: 0.3605 - metric/ndcg_10: 0.4228 - val_loss: 5.5719 - val_metric/ndcg_1: 0.2817 - val_metric/ndcg_3: 0.3411 - val_metric/ndcg_5: 0.3823 - val_metric/ndcg_10: 0.4255\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.1474 - metric/ndcg_1: 0.2873 - metric/ndcg_3: 0.3290 - metric/ndcg_5: 0.3626 - metric/ndcg_10: 0.4275 - val_loss: 5.5719 - val_metric/ndcg_1: 0.2863 - val_metric/ndcg_3: 0.3585 - val_metric/ndcg_5: 0.3854 - val_metric/ndcg_10: 0.4290\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2036 - metric/ndcg_1: 0.2782 - metric/ndcg_3: 0.3225 - metric/ndcg_5: 0.3565 - metric/ndcg_10: 0.4202 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2863 - val_metric/ndcg_3: 0.3593 - val_metric/ndcg_5: 0.3854 - val_metric/ndcg_10: 0.4275\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2212 - metric/ndcg_1: 0.2726 - metric/ndcg_3: 0.3167 - metric/ndcg_5: 0.3496 - metric/ndcg_10: 0.4118 - val_loss: 5.5721 - val_metric/ndcg_1: 0.2848 - val_metric/ndcg_3: 0.3240 - val_metric/ndcg_5: 0.3736 - val_metric/ndcg_10: 0.4100\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2900 - metric/ndcg_1: 0.2740 - metric/ndcg_3: 0.3209 - metric/ndcg_5: 0.3533 - metric/ndcg_10: 0.4169 - val_loss: 5.5720 - val_metric/ndcg_1: 0.2827 - val_metric/ndcg_3: 0.3478 - val_metric/ndcg_5: 0.3804 - val_metric/ndcg_10: 0.4240\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2604 - metric/ndcg_1: 0.2783 - metric/ndcg_3: 0.3249 - metric/ndcg_5: 0.3585 - metric/ndcg_10: 0.4190 - val_loss: 5.5720 - val_metric/ndcg_1: 0.2827 - val_metric/ndcg_3: 0.3481 - val_metric/ndcg_5: 0.3776 - val_metric/ndcg_10: 0.4243\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.2194 - metric/ndcg_1: 0.2825 - metric/ndcg_3: 0.3283 - metric/ndcg_5: 0.3634 - metric/ndcg_10: 0.4269 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2863 - val_metric/ndcg_3: 0.3545 - val_metric/ndcg_5: 0.3855 - val_metric/ndcg_10: 0.4288\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.1261 - metric/ndcg_1: 0.2746 - metric/ndcg_3: 0.3183 - metric/ndcg_5: 0.3521 - metric/ndcg_10: 0.4165 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2863 - val_metric/ndcg_3: 0.3547 - val_metric/ndcg_5: 0.3823 - val_metric/ndcg_10: 0.4280\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.1383 - metric/ndcg_1: 0.2817 - metric/ndcg_3: 0.3278 - metric/ndcg_5: 0.3608 - metric/ndcg_10: 0.4240 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2863 - val_metric/ndcg_3: 0.3437 - val_metric/ndcg_5: 0.3821 - val_metric/ndcg_10: 0.4302\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 5.1335 - metric/ndcg_1: 0.2930 - metric/ndcg_3: 0.3312 - metric/ndcg_5: 0.3639 - metric/ndcg_10: 0.4256 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2815 - val_metric/ndcg_3: 0.3252 - val_metric/ndcg_5: 0.3763 - val_metric/ndcg_10: 0.4253\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 5.3455 - metric/ndcg_1: 0.2729 - metric/ndcg_3: 0.3238 - metric/ndcg_5: 0.3574 - metric/ndcg_10: 0.4197 - val_loss: 5.5719 - val_metric/ndcg_1: 0.2780 - val_metric/ndcg_3: 0.3151 - val_metric/ndcg_5: 0.3653 - val_metric/ndcg_10: 0.4228\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2457 - metric/ndcg_1: 0.2893 - metric/ndcg_3: 0.3339 - metric/ndcg_5: 0.3666 - metric/ndcg_10: 0.4276 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2875 - val_metric/ndcg_3: 0.3375 - val_metric/ndcg_5: 0.3741 - val_metric/ndcg_10: 0.4315\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2205 - metric/ndcg_1: 0.2852 - metric/ndcg_3: 0.3320 - metric/ndcg_5: 0.3672 - metric/ndcg_10: 0.4290 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2815 - val_metric/ndcg_3: 0.3134 - val_metric/ndcg_5: 0.3661 - val_metric/ndcg_10: 0.4233\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1589 - metric/ndcg_1: 0.2846 - metric/ndcg_3: 0.3300 - metric/ndcg_5: 0.3621 - metric/ndcg_10: 0.4250 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2767 - val_metric/ndcg_3: 0.3332 - val_metric/ndcg_5: 0.3684 - val_metric/ndcg_10: 0.4248\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2762 - metric/ndcg_1: 0.2794 - metric/ndcg_3: 0.3271 - metric/ndcg_5: 0.3568 - metric/ndcg_10: 0.4202 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2815 - val_metric/ndcg_3: 0.3223 - val_metric/ndcg_5: 0.3694 - val_metric/ndcg_10: 0.4206\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2169 - metric/ndcg_1: 0.2821 - metric/ndcg_3: 0.3273 - metric/ndcg_5: 0.3599 - metric/ndcg_10: 0.4234 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2732 - val_metric/ndcg_3: 0.3203 - val_metric/ndcg_5: 0.3713 - val_metric/ndcg_10: 0.4211\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1540 - metric/ndcg_1: 0.2827 - metric/ndcg_3: 0.3299 - metric/ndcg_5: 0.3631 - metric/ndcg_10: 0.4253 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2732 - val_metric/ndcg_3: 0.3232 - val_metric/ndcg_5: 0.3724 - val_metric/ndcg_10: 0.4201\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2410 - metric/ndcg_1: 0.2793 - metric/ndcg_3: 0.3262 - metric/ndcg_5: 0.3600 - metric/ndcg_10: 0.4230 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2780 - val_metric/ndcg_3: 0.3090 - val_metric/ndcg_5: 0.3628 - val_metric/ndcg_10: 0.4220\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1261 - metric/ndcg_1: 0.2951 - metric/ndcg_3: 0.3359 - metric/ndcg_5: 0.3689 - metric/ndcg_10: 0.4301 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2815 - val_metric/ndcg_3: 0.3063 - val_metric/ndcg_5: 0.3630 - val_metric/ndcg_10: 0.4181\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.0418 - metric/ndcg_1: 0.2855 - metric/ndcg_3: 0.3314 - metric/ndcg_5: 0.3649 - metric/ndcg_10: 0.4253 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2780 - val_metric/ndcg_3: 0.3057 - val_metric/ndcg_5: 0.3617 - val_metric/ndcg_10: 0.4179\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2444 - metric/ndcg_1: 0.2858 - metric/ndcg_3: 0.3304 - metric/ndcg_5: 0.3623 - metric/ndcg_10: 0.4256 - val_loss: 5.5719 - val_metric/ndcg_1: 0.2803 - val_metric/ndcg_3: 0.3043 - val_metric/ndcg_5: 0.3619 - val_metric/ndcg_10: 0.4132\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2628 - metric/ndcg_1: 0.2832 - metric/ndcg_3: 0.3299 - metric/ndcg_5: 0.3625 - metric/ndcg_10: 0.4239 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2769 - val_metric/ndcg_3: 0.3055 - val_metric/ndcg_5: 0.3624 - val_metric/ndcg_10: 0.4119\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2107 - metric/ndcg_1: 0.2802 - metric/ndcg_3: 0.3256 - metric/ndcg_5: 0.3594 - metric/ndcg_10: 0.4222 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2780 - val_metric/ndcg_3: 0.3070 - val_metric/ndcg_5: 0.3638 - val_metric/ndcg_10: 0.4157\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1816 - metric/ndcg_1: 0.2802 - metric/ndcg_3: 0.3289 - metric/ndcg_5: 0.3635 - metric/ndcg_10: 0.4269 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2780 - val_metric/ndcg_3: 0.3066 - val_metric/ndcg_5: 0.3603 - val_metric/ndcg_10: 0.4121\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1354 - metric/ndcg_1: 0.2839 - metric/ndcg_3: 0.3284 - metric/ndcg_5: 0.3618 - metric/ndcg_10: 0.4258 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2789 - val_metric/ndcg_3: 0.3093 - val_metric/ndcg_5: 0.3633 - val_metric/ndcg_10: 0.4113\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2451 - metric/ndcg_1: 0.2899 - metric/ndcg_3: 0.3335 - metric/ndcg_5: 0.3661 - metric/ndcg_10: 0.4258 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2760 - val_metric/ndcg_3: 0.3171 - val_metric/ndcg_5: 0.3635 - val_metric/ndcg_10: 0.4147\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2460 - metric/ndcg_1: 0.2865 - metric/ndcg_3: 0.3314 - metric/ndcg_5: 0.3650 - metric/ndcg_10: 0.4276 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2769 - val_metric/ndcg_3: 0.3094 - val_metric/ndcg_5: 0.3668 - val_metric/ndcg_10: 0.4168\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1456 - metric/ndcg_1: 0.2866 - metric/ndcg_3: 0.3353 - metric/ndcg_5: 0.3689 - metric/ndcg_10: 0.4325 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2778 - val_metric/ndcg_3: 0.3069 - val_metric/ndcg_5: 0.3560 - val_metric/ndcg_10: 0.4108\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2706 - metric/ndcg_1: 0.2840 - metric/ndcg_3: 0.3322 - metric/ndcg_5: 0.3672 - metric/ndcg_10: 0.4289 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2732 - val_metric/ndcg_3: 0.3054 - val_metric/ndcg_5: 0.3616 - val_metric/ndcg_10: 0.4098\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1666 - metric/ndcg_1: 0.2802 - metric/ndcg_3: 0.3217 - metric/ndcg_5: 0.3566 - metric/ndcg_10: 0.4196 - val_loss: 5.5713 - val_metric/ndcg_1: 0.2897 - val_metric/ndcg_3: 0.3120 - val_metric/ndcg_5: 0.3625 - val_metric/ndcg_10: 0.4129\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.3018 - metric/ndcg_1: 0.2846 - metric/ndcg_3: 0.3281 - metric/ndcg_5: 0.3636 - metric/ndcg_10: 0.4264 - val_loss: 5.5712 - val_metric/ndcg_1: 0.2804 - val_metric/ndcg_3: 0.3109 - val_metric/ndcg_5: 0.3608 - val_metric/ndcg_10: 0.4138\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1096 - metric/ndcg_1: 0.2866 - metric/ndcg_3: 0.3308 - metric/ndcg_5: 0.3659 - metric/ndcg_10: 0.4267 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2753 - val_metric/ndcg_3: 0.3078 - val_metric/ndcg_5: 0.3617 - val_metric/ndcg_10: 0.4117\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.3279 - metric/ndcg_1: 0.2876 - metric/ndcg_3: 0.3333 - metric/ndcg_5: 0.3683 - metric/ndcg_10: 0.4308 - val_loss: 5.5713 - val_metric/ndcg_1: 0.2897 - val_metric/ndcg_3: 0.3133 - val_metric/ndcg_5: 0.3526 - val_metric/ndcg_10: 0.4139\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1109 - metric/ndcg_1: 0.2898 - metric/ndcg_3: 0.3355 - metric/ndcg_5: 0.3678 - metric/ndcg_10: 0.4289 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2702 - val_metric/ndcg_3: 0.3086 - val_metric/ndcg_5: 0.3600 - val_metric/ndcg_10: 0.4130\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.0490 - metric/ndcg_1: 0.2858 - metric/ndcg_3: 0.3310 - metric/ndcg_5: 0.3658 - metric/ndcg_10: 0.4299 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2897 - val_metric/ndcg_3: 0.3138 - val_metric/ndcg_5: 0.3649 - val_metric/ndcg_10: 0.4130\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1643 - metric/ndcg_1: 0.2824 - metric/ndcg_3: 0.3292 - metric/ndcg_5: 0.3622 - metric/ndcg_10: 0.4268 - val_loss: 5.5720 - val_metric/ndcg_1: 0.2793 - val_metric/ndcg_3: 0.2976 - val_metric/ndcg_5: 0.3452 - val_metric/ndcg_10: 0.4034\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.3231 - metric/ndcg_1: 0.2925 - metric/ndcg_3: 0.3351 - metric/ndcg_5: 0.3681 - metric/ndcg_10: 0.4307 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2780 - val_metric/ndcg_3: 0.3087 - val_metric/ndcg_5: 0.3537 - val_metric/ndcg_10: 0.4104\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2038 - metric/ndcg_1: 0.2933 - metric/ndcg_3: 0.3384 - metric/ndcg_5: 0.3708 - metric/ndcg_10: 0.4310 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2769 - val_metric/ndcg_3: 0.3107 - val_metric/ndcg_5: 0.3501 - val_metric/ndcg_10: 0.4099\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.1226 - metric/ndcg_1: 0.2879 - metric/ndcg_3: 0.3321 - metric/ndcg_5: 0.3650 - metric/ndcg_10: 0.4276 - val_loss: 5.5713 - val_metric/ndcg_1: 0.2897 - val_metric/ndcg_3: 0.3131 - val_metric/ndcg_5: 0.3545 - val_metric/ndcg_10: 0.4145\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2664 - metric/ndcg_1: 0.2830 - metric/ndcg_3: 0.3328 - metric/ndcg_5: 0.3658 - metric/ndcg_10: 0.4270 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2732 - val_metric/ndcg_3: 0.3090 - val_metric/ndcg_5: 0.3512 - val_metric/ndcg_10: 0.4109\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2345 - metric/ndcg_1: 0.2877 - metric/ndcg_3: 0.3355 - metric/ndcg_5: 0.3676 - metric/ndcg_10: 0.4306 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2732 - val_metric/ndcg_3: 0.3095 - val_metric/ndcg_5: 0.3458 - val_metric/ndcg_10: 0.4125\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2342 - metric/ndcg_1: 0.2830 - metric/ndcg_3: 0.3303 - metric/ndcg_5: 0.3649 - metric/ndcg_10: 0.4262 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2897 - val_metric/ndcg_3: 0.3162 - val_metric/ndcg_5: 0.3593 - val_metric/ndcg_10: 0.4141\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2154 - metric/ndcg_1: 0.2917 - metric/ndcg_3: 0.3355 - metric/ndcg_5: 0.3689 - metric/ndcg_10: 0.4303 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3084 - val_metric/ndcg_5: 0.3421 - val_metric/ndcg_10: 0.4125\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 5.2722 - metric/ndcg_1: 0.2805 - metric/ndcg_3: 0.3319 - metric/ndcg_5: 0.3662 - metric/ndcg_10: 0.4290 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3073 - val_metric/ndcg_5: 0.3452 - val_metric/ndcg_10: 0.4082\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1290 - metric/ndcg_1: 0.2890 - metric/ndcg_3: 0.3342 - metric/ndcg_5: 0.3681 - metric/ndcg_10: 0.4310 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2804 - val_metric/ndcg_3: 0.3117 - val_metric/ndcg_5: 0.3478 - val_metric/ndcg_10: 0.4131\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1855 - metric/ndcg_1: 0.2817 - metric/ndcg_3: 0.3322 - metric/ndcg_5: 0.3644 - metric/ndcg_10: 0.4245 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2760 - val_metric/ndcg_3: 0.3117 - val_metric/ndcg_5: 0.3500 - val_metric/ndcg_10: 0.4132\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1238 - metric/ndcg_1: 0.2858 - metric/ndcg_3: 0.3311 - metric/ndcg_5: 0.3654 - metric/ndcg_10: 0.4303 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2760 - val_metric/ndcg_3: 0.3139 - val_metric/ndcg_5: 0.3491 - val_metric/ndcg_10: 0.4131\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.2814 - metric/ndcg_1: 0.2934 - metric/ndcg_3: 0.3415 - metric/ndcg_5: 0.3758 - metric/ndcg_10: 0.4360 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3101 - val_metric/ndcg_5: 0.3443 - val_metric/ndcg_10: 0.4133\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1327 - metric/ndcg_1: 0.2956 - metric/ndcg_3: 0.3442 - metric/ndcg_5: 0.3758 - metric/ndcg_10: 0.4355 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2760 - val_metric/ndcg_3: 0.3144 - val_metric/ndcg_5: 0.3537 - val_metric/ndcg_10: 0.4139\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.3243 - metric/ndcg_1: 0.2880 - metric/ndcg_3: 0.3327 - metric/ndcg_5: 0.3681 - metric/ndcg_10: 0.4299 - val_loss: 5.5718 - val_metric/ndcg_1: 0.2793 - val_metric/ndcg_3: 0.3112 - val_metric/ndcg_5: 0.3487 - val_metric/ndcg_10: 0.4136\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 5.2604 - metric/ndcg_1: 0.2830 - metric/ndcg_3: 0.3314 - metric/ndcg_5: 0.3638 - metric/ndcg_10: 0.4233 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3123 - val_metric/ndcg_5: 0.3558 - val_metric/ndcg_10: 0.4114\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.2369 - metric/ndcg_1: 0.2869 - metric/ndcg_3: 0.3330 - metric/ndcg_5: 0.3663 - metric/ndcg_10: 0.4282 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3074 - val_metric/ndcg_5: 0.3477 - val_metric/ndcg_10: 0.4147\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.3275 - metric/ndcg_1: 0.2925 - metric/ndcg_3: 0.3382 - metric/ndcg_5: 0.3708 - metric/ndcg_10: 0.4314 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2774 - val_metric/ndcg_3: 0.3110 - val_metric/ndcg_5: 0.3580 - val_metric/ndcg_10: 0.4147\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.3389 - metric/ndcg_1: 0.2884 - metric/ndcg_3: 0.3356 - metric/ndcg_5: 0.3692 - metric/ndcg_10: 0.4321 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2753 - val_metric/ndcg_3: 0.3109 - val_metric/ndcg_5: 0.3491 - val_metric/ndcg_10: 0.4137\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1871 - metric/ndcg_1: 0.2933 - metric/ndcg_3: 0.3344 - metric/ndcg_5: 0.3695 - metric/ndcg_10: 0.4319 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3079 - val_metric/ndcg_5: 0.3461 - val_metric/ndcg_10: 0.4144\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.0368 - metric/ndcg_1: 0.2955 - metric/ndcg_3: 0.3400 - metric/ndcg_5: 0.3739 - metric/ndcg_10: 0.4377 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3105 - val_metric/ndcg_5: 0.3457 - val_metric/ndcg_10: 0.4138\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1812 - metric/ndcg_1: 0.2898 - metric/ndcg_3: 0.3377 - metric/ndcg_5: 0.3711 - metric/ndcg_10: 0.4341 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3099 - val_metric/ndcg_5: 0.3488 - val_metric/ndcg_10: 0.4124\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.4135 - metric/ndcg_1: 0.2902 - metric/ndcg_3: 0.3362 - metric/ndcg_5: 0.3683 - metric/ndcg_10: 0.4284 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3116 - val_metric/ndcg_5: 0.3481 - val_metric/ndcg_10: 0.4124\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1048 - metric/ndcg_1: 0.2924 - metric/ndcg_3: 0.3363 - metric/ndcg_5: 0.3698 - metric/ndcg_10: 0.4319 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3068 - val_metric/ndcg_5: 0.3443 - val_metric/ndcg_10: 0.4094\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1653 - metric/ndcg_1: 0.2917 - metric/ndcg_3: 0.3343 - metric/ndcg_5: 0.3668 - metric/ndcg_10: 0.4299 - val_loss: 5.5713 - val_metric/ndcg_1: 0.2708 - val_metric/ndcg_3: 0.3101 - val_metric/ndcg_5: 0.3543 - val_metric/ndcg_10: 0.4131\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.2575 - metric/ndcg_1: 0.2824 - metric/ndcg_3: 0.3291 - metric/ndcg_5: 0.3627 - metric/ndcg_10: 0.4234 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3069 - val_metric/ndcg_5: 0.3466 - val_metric/ndcg_10: 0.4131\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1183 - metric/ndcg_1: 0.2911 - metric/ndcg_3: 0.3402 - metric/ndcg_5: 0.3728 - metric/ndcg_10: 0.4340 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2774 - val_metric/ndcg_3: 0.3130 - val_metric/ndcg_5: 0.3496 - val_metric/ndcg_10: 0.4164\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.2653 - metric/ndcg_1: 0.2857 - metric/ndcg_3: 0.3318 - metric/ndcg_5: 0.3654 - metric/ndcg_10: 0.4261 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2789 - val_metric/ndcg_3: 0.3085 - val_metric/ndcg_5: 0.3576 - val_metric/ndcg_10: 0.4160\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.0934 - metric/ndcg_1: 0.2929 - metric/ndcg_3: 0.3373 - metric/ndcg_5: 0.3713 - metric/ndcg_10: 0.4335 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3107 - val_metric/ndcg_5: 0.3465 - val_metric/ndcg_10: 0.4123\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.1002 - metric/ndcg_1: 0.2874 - metric/ndcg_3: 0.3360 - metric/ndcg_5: 0.3680 - metric/ndcg_10: 0.4296 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2778 - val_metric/ndcg_3: 0.3130 - val_metric/ndcg_5: 0.3568 - val_metric/ndcg_10: 0.4153\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.3841 - metric/ndcg_1: 0.2888 - metric/ndcg_3: 0.3352 - metric/ndcg_5: 0.3675 - metric/ndcg_10: 0.4289 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2785 - val_metric/ndcg_3: 0.3129 - val_metric/ndcg_5: 0.3530 - val_metric/ndcg_10: 0.4177\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.0791 - metric/ndcg_1: 0.2900 - metric/ndcg_3: 0.3376 - metric/ndcg_5: 0.3714 - metric/ndcg_10: 0.4342 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3112 - val_metric/ndcg_5: 0.3478 - val_metric/ndcg_10: 0.4136\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.3323 - metric/ndcg_1: 0.2763 - metric/ndcg_3: 0.3284 - metric/ndcg_5: 0.3648 - metric/ndcg_10: 0.4261 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3085 - val_metric/ndcg_5: 0.3516 - val_metric/ndcg_10: 0.4116\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 5.2062 - metric/ndcg_1: 0.2874 - metric/ndcg_3: 0.3371 - metric/ndcg_5: 0.3712 - metric/ndcg_10: 0.4337 - val_loss: 5.5713 - val_metric/ndcg_1: 0.2911 - val_metric/ndcg_3: 0.3215 - val_metric/ndcg_5: 0.3549 - val_metric/ndcg_10: 0.4185\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 5.1158 - metric/ndcg_1: 0.2847 - metric/ndcg_3: 0.3336 - metric/ndcg_5: 0.3675 - metric/ndcg_10: 0.4301 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3155 - val_metric/ndcg_5: 0.3508 - val_metric/ndcg_10: 0.4126\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 5.2900 - metric/ndcg_1: 0.2968 - metric/ndcg_3: 0.3438 - metric/ndcg_5: 0.3755 - metric/ndcg_10: 0.4381 - val_loss: 5.5713 - val_metric/ndcg_1: 0.2722 - val_metric/ndcg_3: 0.3114 - val_metric/ndcg_5: 0.3504 - val_metric/ndcg_10: 0.4095\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 5.0717 - metric/ndcg_1: 0.2912 - metric/ndcg_3: 0.3368 - metric/ndcg_5: 0.3691 - metric/ndcg_10: 0.4321 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3064 - val_metric/ndcg_5: 0.3492 - val_metric/ndcg_10: 0.4104\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 5.2942 - metric/ndcg_1: 0.2889 - metric/ndcg_3: 0.3366 - metric/ndcg_5: 0.3696 - metric/ndcg_10: 0.4338 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3090 - val_metric/ndcg_5: 0.3500 - val_metric/ndcg_10: 0.4131\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 5.2316 - metric/ndcg_1: 0.2983 - metric/ndcg_3: 0.3389 - metric/ndcg_5: 0.3710 - metric/ndcg_10: 0.4340 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3155 - val_metric/ndcg_5: 0.3508 - val_metric/ndcg_10: 0.4171\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 5.1469 - metric/ndcg_1: 0.2835 - metric/ndcg_3: 0.3297 - metric/ndcg_5: 0.3645 - metric/ndcg_10: 0.4287 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3137 - val_metric/ndcg_5: 0.3505 - val_metric/ndcg_10: 0.4172\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 5.3921 - metric/ndcg_1: 0.2884 - metric/ndcg_3: 0.3363 - metric/ndcg_5: 0.3720 - metric/ndcg_10: 0.4322 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3132 - val_metric/ndcg_5: 0.3525 - val_metric/ndcg_10: 0.4152\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 5.0755 - metric/ndcg_1: 0.2924 - metric/ndcg_3: 0.3381 - metric/ndcg_5: 0.3715 - metric/ndcg_10: 0.4342 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3132 - val_metric/ndcg_5: 0.3470 - val_metric/ndcg_10: 0.4121\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 5.3434 - metric/ndcg_1: 0.2874 - metric/ndcg_3: 0.3341 - metric/ndcg_5: 0.3671 - metric/ndcg_10: 0.4295 - val_loss: 5.5717 - val_metric/ndcg_1: 0.2793 - val_metric/ndcg_3: 0.3135 - val_metric/ndcg_5: 0.3462 - val_metric/ndcg_10: 0.4076\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 5.1098 - metric/ndcg_1: 0.2849 - metric/ndcg_3: 0.3329 - metric/ndcg_5: 0.3665 - metric/ndcg_10: 0.4288 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2774 - val_metric/ndcg_3: 0.3122 - val_metric/ndcg_5: 0.3532 - val_metric/ndcg_10: 0.4152\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 5.2914 - metric/ndcg_1: 0.2889 - metric/ndcg_3: 0.3389 - metric/ndcg_5: 0.3718 - metric/ndcg_10: 0.4337 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3207 - val_metric/ndcg_5: 0.3495 - val_metric/ndcg_10: 0.4167\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 5.2953 - metric/ndcg_1: 0.2865 - metric/ndcg_3: 0.3380 - metric/ndcg_5: 0.3722 - metric/ndcg_10: 0.4336 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3151 - val_metric/ndcg_5: 0.3503 - val_metric/ndcg_10: 0.4149\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.0677 - metric/ndcg_1: 0.2935 - metric/ndcg_3: 0.3407 - metric/ndcg_5: 0.3748 - metric/ndcg_10: 0.4376 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3176 - val_metric/ndcg_5: 0.3499 - val_metric/ndcg_10: 0.4128\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.1406 - metric/ndcg_1: 0.2906 - metric/ndcg_3: 0.3361 - metric/ndcg_5: 0.3722 - metric/ndcg_10: 0.4327 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3152 - val_metric/ndcg_5: 0.3616 - val_metric/ndcg_10: 0.4091\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 5.1804 - metric/ndcg_1: 0.2881 - metric/ndcg_3: 0.3347 - metric/ndcg_5: 0.3692 - metric/ndcg_10: 0.4319 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3164 - val_metric/ndcg_5: 0.3560 - val_metric/ndcg_10: 0.4092\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 5.2385 - metric/ndcg_1: 0.2901 - metric/ndcg_3: 0.3323 - metric/ndcg_5: 0.3666 - metric/ndcg_10: 0.4310 - val_loss: 5.5714 - val_metric/ndcg_1: 0.2778 - val_metric/ndcg_3: 0.3108 - val_metric/ndcg_5: 0.3545 - val_metric/ndcg_10: 0.4196\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.2178 - metric/ndcg_1: 0.2885 - metric/ndcg_3: 0.3353 - metric/ndcg_5: 0.3684 - metric/ndcg_10: 0.4297 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3195 - val_metric/ndcg_5: 0.3461 - val_metric/ndcg_10: 0.4104\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.1346 - metric/ndcg_1: 0.2870 - metric/ndcg_3: 0.3350 - metric/ndcg_5: 0.3668 - metric/ndcg_10: 0.4295 - val_loss: 5.5715 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3192 - val_metric/ndcg_5: 0.3531 - val_metric/ndcg_10: 0.4178\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 5.0479 - metric/ndcg_1: 0.2948 - metric/ndcg_3: 0.3362 - metric/ndcg_5: 0.3700 - metric/ndcg_10: 0.4341 - val_loss: 5.5716 - val_metric/ndcg_1: 0.2721 - val_metric/ndcg_3: 0.3154 - val_metric/ndcg_5: 0.3534 - val_metric/ndcg_10: 0.4106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f07695c820>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(_MODEL_DIR)\n",
    "\n",
    "\n",
    "ranker.fit(train_dataset,\n",
    "           validation_data=vali_dataset,\n",
    "           steps_per_epoch=100,\n",
    "           epochs=100,\n",
    "           validation_steps=1,\n",
    "           callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53141e0b-acee-4873-937c-416bcab5418a",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e608c-296b-4efc-bffc-88deaeeecdfe",
   "metadata": {},
   "source": [
    "#### TensorBoard for Train & Eval tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ef6880cc-166a-4325-882f-53484e584157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 27076), started 12:03:44 ago. (Use '!kill 27076' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e886648f48fd1a3b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e886648f48fd1a3b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./Models #--port 25952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cea062ba-8c24-4275-ac48-33b50477b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The tensorboard extension is already loaded. To reload it, use:\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3147c6-325e-4c77-a141-bff91f1e32f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
