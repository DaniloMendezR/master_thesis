{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGgPRppP7kri","executionInfo":{"status":"ok","timestamp":1652184018038,"user_tz":-120,"elapsed":18783,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}},"outputId":"f970fecb-e472-4ebf-fa75-440b1c5fc151"},"id":"rGgPRppP7kri","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"id":"fb37a4b7-a510-4c43-9cbb-4540460db697","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fb37a4b7-a510-4c43-9cbb-4540460db697","executionInfo":{"status":"ok","timestamp":1652184027790,"user_tz":-120,"elapsed":9758,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}},"outputId":"5822a4a5-5492-49dc-d6c6-d6ae38a70d2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 462 kB 7.5 MB/s \n","\u001b[K     |████████████████████████████████| 141 kB 7.4 MB/s \n","\u001b[?25h"]}],"source":["!pip install -q tensorflow\n","!pip install -q tensorflow_ranking"]},{"cell_type":"code","execution_count":4,"id":"097104e6-1103-4afa-8619-c9f824c0fe06","metadata":{"id":"097104e6-1103-4afa-8619-c9f824c0fe06","executionInfo":{"status":"ok","timestamp":1652184028162,"user_tz":-120,"elapsed":378,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import datetime as dt\n","import os\n","\n","#PATH = os.getcwd()\n","PATH = '/content/drive/Shareddrives/Master Tesis/Tesis'"]},{"cell_type":"code","execution_count":5,"id":"1be38527-841e-405c-be81-bbb6b63cbd4f","metadata":{"id":"1be38527-841e-405c-be81-bbb6b63cbd4f","executionInfo":{"status":"ok","timestamp":1652184030952,"user_tz":-120,"elapsed":2795,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}}},"outputs":[],"source":["import tensorflow_ranking as tfr\n","import tensorflow as tf\n","from tensorflow_serving.apis import input_pb2"]},{"cell_type":"markdown","id":"9eec5900-63e0-4792-8723-95b38b8cd26e","metadata":{"id":"9eec5900-63e0-4792-8723-95b38b8cd26e"},"source":["## Import Tables"]},{"cell_type":"code","execution_count":6,"id":"6da9c646-6efc-4578-adaa-1a026e748b81","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":413},"id":"6da9c646-6efc-4578-adaa-1a026e748b81","executionInfo":{"status":"ok","timestamp":1652184036042,"user_tz":-120,"elapsed":5096,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}},"outputId":"04ff27a0-cdff-4425-a109-6d68e25d779a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                AAL       AAPL  ABBV        ABC        ABT      ADP  \\\n","Date                                                                  \n","2012-01-08   8.4760  13.162167   NaN   0.404000 -24.607200      NaN   \n","2012-01-15      NaN  11.965000   NaN  -4.760143  -3.706000      NaN   \n","2012-01-22   9.9768 -10.776667   NaN -17.240429 -22.233833      NaN   \n","2012-01-29 -20.9400  -9.334000   NaN  11.740000  -8.165800 -42.6148   \n","2012-02-05      NaN -33.438857   NaN  -2.313000 -30.020400 -39.8710   \n","\n","                  AIG        AMD       AMZN        AXP  ...        UAL  \\\n","Date                                                    ...              \n","2012-01-08        NaN        NaN  -3.370000        NaN  ...  12.493714   \n","2012-01-15 -11.584333  16.834600 -18.815571 -10.443167  ...  12.935143   \n","2012-01-22 -10.898400        NaN  15.001167   0.860833  ...   2.058714   \n","2012-01-29 -22.226000        NaN  -7.894167 -33.329167  ...   9.101000   \n","2012-02-05 -18.959800 -30.327667  -3.668714 -20.110167  ...  -5.529429   \n","\n","                  UNH      UPS        USB          V         VZ        WFC  \\\n","Date                                                                         \n","2012-01-08        NaN  -9.7618   8.849167        NaN   8.031400   7.316500   \n","2012-01-15  11.435500  -1.2800 -17.410857 -33.085800 -10.427667  21.078333   \n","2012-01-22  17.216800  -8.6162 -24.026800        NaN -31.776000  -0.758500   \n","2012-01-29        NaN  22.8662 -52.884000        NaN   8.221000 -20.201500   \n","2012-02-05 -36.037833   4.4648 -42.687167  14.249667 -47.767143  -7.948200   \n","\n","                  WMT      WY        XOM  \n","Date                                      \n","2012-01-08  33.678600     NaN   1.957143  \n","2012-01-15  15.656600     NaN -18.020000  \n","2012-01-22 -14.170714     NaN -19.522714  \n","2012-01-29   0.036800     NaN   6.625571  \n","2012-02-05 -45.108167 -28.786   8.348429  \n","\n","[5 rows x 108 columns]"],"text/html":["\n","  <div id=\"df-c090bf30-7d6c-4095-8626-9e36bea3ab25\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AAL</th>\n","      <th>AAPL</th>\n","      <th>ABBV</th>\n","      <th>ABC</th>\n","      <th>ABT</th>\n","      <th>ADP</th>\n","      <th>AIG</th>\n","      <th>AMD</th>\n","      <th>AMZN</th>\n","      <th>AXP</th>\n","      <th>...</th>\n","      <th>UAL</th>\n","      <th>UNH</th>\n","      <th>UPS</th>\n","      <th>USB</th>\n","      <th>V</th>\n","      <th>VZ</th>\n","      <th>WFC</th>\n","      <th>WMT</th>\n","      <th>WY</th>\n","      <th>XOM</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2012-01-08</th>\n","      <td>8.4760</td>\n","      <td>13.162167</td>\n","      <td>NaN</td>\n","      <td>0.404000</td>\n","      <td>-24.607200</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-3.370000</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>12.493714</td>\n","      <td>NaN</td>\n","      <td>-9.7618</td>\n","      <td>8.849167</td>\n","      <td>NaN</td>\n","      <td>8.031400</td>\n","      <td>7.316500</td>\n","      <td>33.678600</td>\n","      <td>NaN</td>\n","      <td>1.957143</td>\n","    </tr>\n","    <tr>\n","      <th>2012-01-15</th>\n","      <td>NaN</td>\n","      <td>11.965000</td>\n","      <td>NaN</td>\n","      <td>-4.760143</td>\n","      <td>-3.706000</td>\n","      <td>NaN</td>\n","      <td>-11.584333</td>\n","      <td>16.834600</td>\n","      <td>-18.815571</td>\n","      <td>-10.443167</td>\n","      <td>...</td>\n","      <td>12.935143</td>\n","      <td>11.435500</td>\n","      <td>-1.2800</td>\n","      <td>-17.410857</td>\n","      <td>-33.085800</td>\n","      <td>-10.427667</td>\n","      <td>21.078333</td>\n","      <td>15.656600</td>\n","      <td>NaN</td>\n","      <td>-18.020000</td>\n","    </tr>\n","    <tr>\n","      <th>2012-01-22</th>\n","      <td>9.9768</td>\n","      <td>-10.776667</td>\n","      <td>NaN</td>\n","      <td>-17.240429</td>\n","      <td>-22.233833</td>\n","      <td>NaN</td>\n","      <td>-10.898400</td>\n","      <td>NaN</td>\n","      <td>15.001167</td>\n","      <td>0.860833</td>\n","      <td>...</td>\n","      <td>2.058714</td>\n","      <td>17.216800</td>\n","      <td>-8.6162</td>\n","      <td>-24.026800</td>\n","      <td>NaN</td>\n","      <td>-31.776000</td>\n","      <td>-0.758500</td>\n","      <td>-14.170714</td>\n","      <td>NaN</td>\n","      <td>-19.522714</td>\n","    </tr>\n","    <tr>\n","      <th>2012-01-29</th>\n","      <td>-20.9400</td>\n","      <td>-9.334000</td>\n","      <td>NaN</td>\n","      <td>11.740000</td>\n","      <td>-8.165800</td>\n","      <td>-42.6148</td>\n","      <td>-22.226000</td>\n","      <td>NaN</td>\n","      <td>-7.894167</td>\n","      <td>-33.329167</td>\n","      <td>...</td>\n","      <td>9.101000</td>\n","      <td>NaN</td>\n","      <td>22.8662</td>\n","      <td>-52.884000</td>\n","      <td>NaN</td>\n","      <td>8.221000</td>\n","      <td>-20.201500</td>\n","      <td>0.036800</td>\n","      <td>NaN</td>\n","      <td>6.625571</td>\n","    </tr>\n","    <tr>\n","      <th>2012-02-05</th>\n","      <td>NaN</td>\n","      <td>-33.438857</td>\n","      <td>NaN</td>\n","      <td>-2.313000</td>\n","      <td>-30.020400</td>\n","      <td>-39.8710</td>\n","      <td>-18.959800</td>\n","      <td>-30.327667</td>\n","      <td>-3.668714</td>\n","      <td>-20.110167</td>\n","      <td>...</td>\n","      <td>-5.529429</td>\n","      <td>-36.037833</td>\n","      <td>4.4648</td>\n","      <td>-42.687167</td>\n","      <td>14.249667</td>\n","      <td>-47.767143</td>\n","      <td>-7.948200</td>\n","      <td>-45.108167</td>\n","      <td>-28.786</td>\n","      <td>8.348429</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 108 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c090bf30-7d6c-4095-8626-9e36bea3ab25')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c090bf30-7d6c-4095-8626-9e36bea3ab25 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c090bf30-7d6c-4095-8626-9e36bea3ab25');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["tables_names = ['big_log_ret','big_RCV', 'big_RVT', 'big_positivePartscr', 'big_negativePartscr', 'big_splogscr', 'big_linscr']\n","tables_dict = {}\n","for name in tables_names:\n","    table = pd.read_csv(os.path.join(PATH, 'Tables', name+'.csv'))\n","    table['Date'] = pd.to_datetime(table['Date']).dt.date\n","    table.set_index('Date', inplace=True)\n","    tables_dict[name] = table\n","\n","tables_dict['big_RCV'].head()"]},{"cell_type":"markdown","id":"dd7eba07-f2c0-49fe-87a8-f57804e4c39e","metadata":{"id":"dd7eba07-f2c0-49fe-87a8-f57804e4c39e"},"source":["## Merging Tables - Building the query-stock final table"]},{"cell_type":"code","execution_count":9,"id":"f47e7f6b-00b3-41b6-be1a-7528539882ed","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"f47e7f6b-00b3-41b6-be1a-7528539882ed","executionInfo":{"status":"ok","timestamp":1652184039643,"user_tz":-120,"elapsed":651,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}},"outputId":"70a14784-5cea-4fb4-a6f6-1f2260733644"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Query Ticker  big_log_ret    big_RCV   big_RVT  \\\n","0      2012-01-08    AAL     0.063980   8.476000  0.000280   \n","1      2012-01-08   AAPL    -0.006151  13.162167  0.003400   \n","2      2012-01-08    ABC    -0.020684   0.404000  0.000760   \n","3      2012-01-08    ABT     0.000863 -24.607200  0.000320   \n","4      2012-01-08   AMZN    -0.023212  -3.370000  0.001100   \n","...           ...    ...          ...        ...       ...   \n","41819  2021-11-28    UPS    -0.022512 -42.160333  0.000317   \n","41820  2021-11-28    USB    -0.033782 -28.514833  0.000483   \n","41821  2021-11-28     VZ    -0.007363 -22.016000  0.000686   \n","41822  2021-11-28    WFC    -0.014140 -37.779000  0.000983   \n","41823  2021-11-28    WMT    -0.052347 -12.486143  0.000643   \n","\n","       big_positivePartscr  big_negativePartscr  big_splogscr  big_linscr  \n","0                 0.020240             0.013340      0.010760   54.733580  \n","1                 0.016050             0.015650      0.020333   48.380133  \n","2                 0.027820             0.012980      0.017000   65.547120  \n","3                 0.010820             0.018540     -0.012980   27.375300  \n","4                 0.016180             0.020000     -0.024640   40.688020  \n","...                    ...                  ...           ...         ...  \n","41819             0.018200             0.024717     -0.008817   46.677617  \n","41820             0.020517             0.010367      0.037033   68.229333  \n","41821             0.018957             0.036629     -0.066443   28.958114  \n","41822             0.004283             0.017333     -0.061550   15.077883  \n","41823             0.020143             0.027329     -0.029786   50.108929  \n","\n","[41824 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-c7555b4d-b9c7-4c84-adbf-fee529ae18af\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Query</th>\n","      <th>Ticker</th>\n","      <th>big_log_ret</th>\n","      <th>big_RCV</th>\n","      <th>big_RVT</th>\n","      <th>big_positivePartscr</th>\n","      <th>big_negativePartscr</th>\n","      <th>big_splogscr</th>\n","      <th>big_linscr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2012-01-08</td>\n","      <td>AAL</td>\n","      <td>0.063980</td>\n","      <td>8.476000</td>\n","      <td>0.000280</td>\n","      <td>0.020240</td>\n","      <td>0.013340</td>\n","      <td>0.010760</td>\n","      <td>54.733580</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2012-01-08</td>\n","      <td>AAPL</td>\n","      <td>-0.006151</td>\n","      <td>13.162167</td>\n","      <td>0.003400</td>\n","      <td>0.016050</td>\n","      <td>0.015650</td>\n","      <td>0.020333</td>\n","      <td>48.380133</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2012-01-08</td>\n","      <td>ABC</td>\n","      <td>-0.020684</td>\n","      <td>0.404000</td>\n","      <td>0.000760</td>\n","      <td>0.027820</td>\n","      <td>0.012980</td>\n","      <td>0.017000</td>\n","      <td>65.547120</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2012-01-08</td>\n","      <td>ABT</td>\n","      <td>0.000863</td>\n","      <td>-24.607200</td>\n","      <td>0.000320</td>\n","      <td>0.010820</td>\n","      <td>0.018540</td>\n","      <td>-0.012980</td>\n","      <td>27.375300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2012-01-08</td>\n","      <td>AMZN</td>\n","      <td>-0.023212</td>\n","      <td>-3.370000</td>\n","      <td>0.001100</td>\n","      <td>0.016180</td>\n","      <td>0.020000</td>\n","      <td>-0.024640</td>\n","      <td>40.688020</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>41819</th>\n","      <td>2021-11-28</td>\n","      <td>UPS</td>\n","      <td>-0.022512</td>\n","      <td>-42.160333</td>\n","      <td>0.000317</td>\n","      <td>0.018200</td>\n","      <td>0.024717</td>\n","      <td>-0.008817</td>\n","      <td>46.677617</td>\n","    </tr>\n","    <tr>\n","      <th>41820</th>\n","      <td>2021-11-28</td>\n","      <td>USB</td>\n","      <td>-0.033782</td>\n","      <td>-28.514833</td>\n","      <td>0.000483</td>\n","      <td>0.020517</td>\n","      <td>0.010367</td>\n","      <td>0.037033</td>\n","      <td>68.229333</td>\n","    </tr>\n","    <tr>\n","      <th>41821</th>\n","      <td>2021-11-28</td>\n","      <td>VZ</td>\n","      <td>-0.007363</td>\n","      <td>-22.016000</td>\n","      <td>0.000686</td>\n","      <td>0.018957</td>\n","      <td>0.036629</td>\n","      <td>-0.066443</td>\n","      <td>28.958114</td>\n","    </tr>\n","    <tr>\n","      <th>41822</th>\n","      <td>2021-11-28</td>\n","      <td>WFC</td>\n","      <td>-0.014140</td>\n","      <td>-37.779000</td>\n","      <td>0.000983</td>\n","      <td>0.004283</td>\n","      <td>0.017333</td>\n","      <td>-0.061550</td>\n","      <td>15.077883</td>\n","    </tr>\n","    <tr>\n","      <th>41823</th>\n","      <td>2021-11-28</td>\n","      <td>WMT</td>\n","      <td>-0.052347</td>\n","      <td>-12.486143</td>\n","      <td>0.000643</td>\n","      <td>0.020143</td>\n","      <td>0.027329</td>\n","      <td>-0.029786</td>\n","      <td>50.108929</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>41824 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7555b4d-b9c7-4c84-adbf-fee529ae18af')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c7555b4d-b9c7-4c84-adbf-fee529ae18af button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c7555b4d-b9c7-4c84-adbf-fee529ae18af');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["final_table = tables_dict['big_log_ret'].stack() #Stack DF to a Series so that is grouped by Date and then by Ticker\n","final_table.index.names=('Query','Ticker') #Rename 'Date' to 'Query'\n","final_table = final_table.reset_index()\n","final_table.rename(columns={0: 'big_log_ret'}, inplace=True)\n","resting_tables_dict = dict(tables_dict) #Make a copy of the dictionary\n","del resting_tables_dict['big_log_ret'] #Remove the log_ret table\n","\n","for i, t_name in enumerate(resting_tables_dict):\n","    table = tables_dict[t_name].stack()\n","    table.index.names=('Query','Ticker')\n","    table = table.reset_index()\n","    table.rename(columns={0: t_name}, inplace=True)\n","    final_table = pd.merge(final_table, table, on=['Query','Ticker'])\n","\n","final_table"]},{"cell_type":"code","source":["def expanding_window_split(dataframe, number_of_splits:int):\n","    '''\n","    Splits the dataframe into 'number of splits' to train and test sets to predict one period ahead. It produces the number of splits starting from the\n","    last element onwards in a decreasing manner. \n","    '''\n","    all_splits = {}\n","    for i in range(number_of_splits):\n","        test_query = dataframe['Query'].unique()[-(i+1)]\n","        train_query = dataframe['Query'].unique()[:-(i+1)]\n","        test = dataframe[dataframe['Query'].isin([test_query])]\n","        train = dataframe[dataframe['Query'].isin(train_query)]\n","        all_splits[\"split_\"+str(i+1)] = (train, test)\n","    return all_splits"],"metadata":{"id":"IJyLPVb61ofi","executionInfo":{"status":"ok","timestamp":1652185788778,"user_tz":-120,"elapsed":237,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}}},"id":"IJyLPVb61ofi","execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":31,"id":"d1eb957c-0e1e-4295-861b-05c2ade20008","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1eb957c-0e1e-4295-861b-05c2ade20008","executionInfo":{"status":"ok","timestamp":1652179470883,"user_tz":-120,"elapsed":779,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}},"outputId":"3e601661-afb4-414e-e6af-8470e3f6694f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":31}],"source":["'''\n","Aqui tenemos q añadir un filtro para eliminar aquellas filas q tengan un NaN y tambien si queremos hacer algun preprocessing previo\n","'''\n","final_table.isnull().values.any()"]},{"cell_type":"code","source":["'''\n","Es posible que necesitemos pasar todos los log returns a no negativos sumandole el valor absoluto del minimo a toda la columna para que sean positivos\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6oFUdFB8lsy","executionInfo":{"status":"ok","timestamp":1652169114617,"user_tz":-120,"elapsed":235,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}},"outputId":"2f3b0e96-ee9b-489e-86ce-c8055e4dc78b"},"id":"H6oFUdFB8lsy","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## Data Splitting\n","\n","We are looking to split the data to train our model, the problem with time series split train tests is that we use 95% to train the data and test it on the last 5%. There is a possibility that our test data behaves nicely or we just got lucky. To combat this event we do an expanding window test. Where we use some of the data to predict the next period, then we expand the data and repeat. This way we can have a more testing sets with the same data in an appropiate way.  "],"metadata":{"id":"8wPIbh6RkiT9"},"id":"8wPIbh6RkiT9"},{"cell_type":"code","source":[""],"metadata":{"id":"lMT2zdokkiAO"},"id":"lMT2zdokkiAO","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"8ca0e56b-6d92-4733-bbac-844b4da3c95b","metadata":{"id":"8ca0e56b-6d92-4733-bbac-844b4da3c95b"},"outputs":[],"source":["'''\n","Protobuffers are extensible structures suitable for storing data in a serialized format, either locally or in a distributed manner.\n","TF ranking has a couple of pre-defined protobufs such as ELWC which make it easier to integrate and formalize data ingestion into\n","the ranking pipeline.\n","\n","Protocol buffers and the tf.data API is a set of utilities that provide a mechanism to read and store data for efficient loading\n","and preprocessing in a way that's fast and scalable.\n","'''\n","\n","# Class I wrote to organize code resposible for parsing our dataframe data and \n","# creating compressed TF-Records in ELWC protobuf format so that they used by \n","# most rankers in TF-Ranking and be compatible with future rankers or new methods\n","\n","class DFToELWCProto():\n","    \"\"\" Class to parse Dataframe ranking data in ELWC proto TFRecords\"\"\"\n","    \n","    def __init__(self, dir:str=\".\", use_compression:bool=False):\n","        assert isinstance(dir,str)\n","        if not os.path.isdir(dir):\n","            os.mkdir(dir)\n","        self.input_path = dir\n","        assert isinstance(use_compression,bool)\n","        self.compress = use_compression\n","        if self.compress:\n","            self.compress_type = 'GZIP'\n","        else:\n","            self.compress_type = None\n","\n","\n","    # Helper functions (see also https://www.tensorflow.org/tutorials/load_data/tf_records)\n","    def _bytes_feature(self,value_list):\n","        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","        if isinstance(value_list, type(tf.constant(0))):\n","            value_list = value_list.numpy()\n","        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value_list]))\n","\n","    def _float_feature(self,value_list):\n","        \"\"\"Returns a float_list from a float / double.\"\"\"\n","        return tf.train.Feature(float_list=tf.train.FloatList(value=[value_list]))\n","\n","    def _int64_feature(self,value_list):\n","        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value_list]))\n","\n","\n","    def read_and_print_topn_tfrecord(self, target_filename, num_of_examples_to_read):\n","        filenames = [target_filename]\n","        tf_record_dataset = tf.data.TFRecordDataset(filenames,\n","                                                    compression_type=self.compress_type)\n","\n","        for raw_record in tf_record_dataset.take(num_of_examples_to_read):\n","            example_list_with_context = input_pb2.ExampleListWithContext()\n","            example_list_with_context.ParseFromString(raw_record.numpy())\n","            print(example_list_with_context)\n","\n","    def df_to_TFrecord(self, df, file_name):\n","\n","        \"\"\" \n","        for reading and converting directly from arrays in memory\n","\n","        \"\"\"    \n","        file_name = os.path.basename(file_name)\n","\n","        if self.compress:\n","            print('Using GZIP compression for writing ELWC TFRecord Dataset')\n","            opts = tf.io.TFRecordOptions(compression_type = self.compress_type)\n","            file_name = f\"{file_name}.gzipped_tfrecord\"\n","        else:\n","            file_name = f\"{file_name}.tfrecord\"\n","        save_path = f\"{self.input_path}/{file_name}\"\n","\n","        with tf.io.TFRecordWriter(f\"{save_path}\", options=opts) as writer:\n","            \n","            input_array = np.array(df)\n","            col_names = df.columns\n","\n","            ELWC = input_pb2.ExampleListWithContext()\n","            prev_qid = None\n","\n","            for i in range(input_array.shape[0]):\n","\n","                qid, doc, r, features = str(input_array[i,0]), input_array[i,1], input_array[i,2], input_array[i,3:]\n","\n","                example_proto_dict = {\n","                              f\"{col_names[f_n+3]}\":self._float_feature((f_v))\n","                                  for (f_n, f_v) in enumerate(features)\n","                          }\n","                example_proto_dict['rel'] = self._int64_feature(int(r))\n","                #example_proto_dict['doc_name'] = self._bytes_feature(str(doc))\n","\n","                example_proto = tf.train.Example(\n","                            features=tf.train.Features(feature=example_proto_dict))\n","                if qid != prev_qid:\n","                    if prev_qid is not None:\n","                        writer.write(ELWC.SerializeToString())\n","                    prev_qid = qid\n","                    ELWC = input_pb2.ExampleListWithContext()\n","                    ELWC.examples.append(example_proto)\n","                else:\n","                    ELWC.examples.append(example_proto)\n","\n","            # final write for the last query grp\n","            writer.write(ELWC.SerializeToString())"]},{"cell_type":"code","execution_count":null,"id":"39115f8d-8766-4382-b8e7-0dd11c588064","metadata":{"id":"39115f8d-8766-4382-b8e7-0dd11c588064","outputId":"fe9ba8ff-8849-4daf-a2ad-ec6370a7a128"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using GZIP compression for writing ELWC TFRecord Dataset\n"]}],"source":["ELWC_converter = DFToELWCProto(dir =\"./Tables/LTR-tfrecords\",\n","                              use_compression=True)\n","ELWC_converter.df_to_TFrecord(final_table,\"LTR_dataset\")"]},{"cell_type":"code","execution_count":29,"id":"ce2ac05d-a5db-4fb3-b1d1-f5849b5a781d","metadata":{"id":"ce2ac05d-a5db-4fb3-b1d1-f5849b5a781d","executionInfo":{"status":"ok","timestamp":1652174545824,"user_tz":-120,"elapsed":332,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}}},"outputs":[],"source":["# Store the paths to files containing training and test instances.\n","_DATA_PATH = f\"./Tables/LTR-tfrecords.gzip_tfrecord\"\n","\n","# The maximum number of documents per query in the dataset.\n","# Document lists are padded or truncated to this size.\n","_LIST_SIZE = final_table.groupby('Query').size().max()\n","\n","# The document relevance label.\n","_LABEL_FEATURE_NAME = \"big_log_ret\"\n","#number of columns minus the query, ticker and returns\n","_NUM_FEATURES = final_table.shape[1] -3\n","\n","# Padding labels are set negative so that the corresponding examples can be\n","# ignored in loss and metrics.\n","_PADDING_LABEL = -1\n","\n","# Learning rate for optimizer.\n","_LEARNING_RATE = 0.05\n","\n","# Parameters to the scoring function.\n","_BATCH_SIZE = 64\n","_DROPOUT_RATE = 0.3\n","\n","# Location of model directory and number of training steps.\n","_MODEL_DIR = f\"./Models/model_{dt.datetime.now().strftime('%m-%d-%Y_%H-%M-%S')}\"\n","\n","# setting as shell env for tensorboard stuff\n","os.environ[\"models_dir\"] = _MODEL_DIR"]},{"cell_type":"code","source":["def create_feature_columns():\n","\n","  # We dont have context featuresin MSLR datasets\n","  context_feature_columns = {}\n","\n","  feature_names = [\"{}\".format(i + 1) for i in range(_NUM_FEATURES)]\n","  example_feature_columns = {\n","      name:\n","      tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n","      for name in feature_names}\n","\n","  return context_feature_columns, example_feature_columns\n"],"metadata":{"id":"u3424sraP7Lf","executionInfo":{"status":"ok","timestamp":1652174090506,"user_tz":-120,"elapsed":424,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}}},"id":"u3424sraP7Lf","execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":26,"id":"b0140a07-dc74-4f06-9563-e923866f7d55","metadata":{"id":"b0140a07-dc74-4f06-9563-e923866f7d55","executionInfo":{"status":"ok","timestamp":1652174514072,"user_tz":-120,"elapsed":242,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}}},"outputs":[],"source":["def create_dataset_from_tfrecords(input_path:str,\n","                                  batch_sz:int,\n","                                  shuffle:bool = True,\n","                                  num_epochs:int = None,\n","                                  data_format:str = \"ELWC\",\n","                                  compression_type:str = ''):\n","\n","    context_feature_columns, example_feature_columns = create_feature_columns()\n","\n","\n","    context_feature_spec = tf.feature_column.make_parse_example_spec(\n","      context_feature_columns.values())\n","    label_column = tf.feature_column.numeric_column(\n","      _LABEL_FEATURE_NAME, dtype=tf.int64, default_value=_PADDING_LABEL)\n","    example_feature_spec = tf.feature_column.make_parse_example_spec(\n","      list(example_feature_columns.values()) + [label_column])\n","\n","    _reader_arg_list = []\n","    if compression_type:\n","        assert compression_type in [\"\", \"GZIP\",\"ZLIB\"]\n","        _reader_arg_list = [compression_type]\n","\n","\n","    dataset = tfr.data.build_ranking_dataset(\n","      file_pattern=input_path,\n","      data_format=tfr.data.ELWC,\n","      batch_size=batch_sz,\n","      list_size=_LIST_SIZE,\n","      context_feature_spec=context_feature_spec,\n","      example_feature_spec=example_feature_spec,\n","      reader=tf.data.TFRecordDataset,\n","      reader_args= _reader_arg_list,\n","      shuffle=shuffle,\n","      num_epochs=num_epochs,\n","      )\n","\n","    def _log1p_transform(features):\n","        '''\n","        computes elementwise log_e(|x|)*sign(x)\n","        '''\n","    transformed_feats = {\n","        f:tf.math.multiply(\n","            tf.math.log1p(\n","                tf.math.abs(features[f])\n","                ),\n","            tf.math.sign(features[f])\n","            )\n","        for f in features}\n","    return transformed_feats\n","\n","    def _split_label_and_transform_features(features):\n","        label = tf.squeeze(features.pop(_LABEL_FEATURE_NAME), axis=2)\n","        label = tf.cast(label, tf.float32)\n","        features = _log1p_transform(features)\n","\n","    return features, label\n","\n","    dataset = dataset.map(_split_label_and_transform_features)\n","\n","    return dataset"]},{"cell_type":"code","execution_count":30,"id":"971744d9-bd4d-4768-96c0-b062da29d479","metadata":{"id":"971744d9-bd4d-4768-96c0-b062da29d479","executionInfo":{"status":"ok","timestamp":1652174549791,"user_tz":-120,"elapsed":368,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}}},"outputs":[],"source":["context_feature_columns, example_feature_columns = create_feature_columns()\n","# Using a Canned Network\n","ranking_network = tfr.keras.canned.DNNRankingNetwork(\n","      context_feature_columns=context_feature_columns,\n","      example_feature_columns=example_feature_columns,\n","      hidden_layer_dims=[64, 32, 16],\n","      activation=tf.nn.relu,\n","      dropout=_DROPOUT_RATE,\n","      use_batch_norm=True,\n","      batch_norm_moment=0.4)\n"]},{"cell_type":"code","source":["_loss_obj = tfr.keras.losses.get(\n","    tfr.losses.RankingLossKey.GUMBEL_APPROX_NDCG_LOSS)\n","\n","\n","#Different Losses knowing that the softmax loss is representative of the listwise apporach\n","#_loss_obj = tfr.keras.losses.get(\n","#    tfr.losses.RankingLossKey.UNIQUE_SOFTMAX_LOSS)\n","\n","\n","#_loss_obj = tfr.keras.losses.get(\n","#    tfr.losses.RankingLossKey.LIST_MLE_LOSS)\n","\n","\n","#_loss_obj = tfr.keras.losses.get(\n","#    tfr.losses.RankingLossKey.SOFTMAX_LOSS)\n","# Contains all ranking metrics, including NDCG @ {1, 3, 5, 10}.\n","\n","def _make_eval_metric_fns():\n","  \"\"\"Returns a list of ranking metrics for the keras ranker\"\"\"\n","  metric_fns = [tfr.keras.metrics.get(**kwargs) \n","                        for kwargs in [dict(key=\"ndcg\", topn=topn, \n","                                        name=\"metric/ndcg_{}\".format(topn)) \n","                                            for topn in [1, 3, 5, 10]]\n","                ]\n","  return metric_fns\n","\n","default_metrics = _make_eval_metric_fns()\n","\n","config = tf.estimator.RunConfig(\n","      model_dir=_MODEL_DIR,\n","      keep_checkpoint_max=10,\n","      save_checkpoints_secs=200)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"rEPAYHxyOULH","executionInfo":{"status":"error","timestamp":1652173896663,"user_tz":-120,"elapsed":391,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}},"outputId":"fed934cb-3ce8-47f5-fdca-49c11caab2ac"},"id":"rEPAYHxyOULH","execution_count":19,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-acdebe7664f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m config = tf.estimator.RunConfig(\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_MODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mkeep_checkpoint_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       save_checkpoints_secs=200)\n","\u001b[0;31mNameError\u001b[0m: name '_MODEL_DIR' is not defined"]}]},{"cell_type":"code","source":["# Build ranker as a Functional Keras model.\n","ranker = tfr.keras.model.create_keras_model(\n","      network=ranking_network,\n","      loss=_loss_obj,\n","      metrics=default_metrics,\n","      optimizer=tf.keras.optimizers.Adagrad(learning_rate=_LEARNING_RATE),\n","      size_feature_name=None)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOlSC0uZPRJF","executionInfo":{"status":"ok","timestamp":1652173911539,"user_tz":-120,"elapsed":225,"user":{"displayName":"Danilo Méndez","userId":"17401835669463718921"}},"outputId":"ad7c2c6a-5eb7-407e-95aa-d7d088588eae"},"id":"EOlSC0uZPRJF","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tensorflow_ranking.python.keras.metrics.NDCGMetric at 0x7f45c66be9d0>,\n"," <tensorflow_ranking.python.keras.metrics.NDCGMetric at 0x7f45c65ddfd0>,\n"," <tensorflow_ranking.python.keras.metrics.NDCGMetric at 0x7f45c66b7f50>,\n"," <tensorflow_ranking.python.keras.metrics.NDCGMetric at 0x7f45c6462dd0>]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["assert tf.test.gpu_device_name() != '', \"GPU not detected, training is much faster GPU/TPU instance of colab\"\n","\n","train_dataset = create_dataset_from_tfrecords(_TRAIN_DATA_PATH,\n","                                              _BATCH_SIZE,\n","                                              compression_type=\"GZIP\")\n","\n","vali_dataset = create_dataset_from_tfrecords(_VALID_DATA_PATH,\n","                                             _BATCH_SIZE,\n","                                             shuffle=False,\n","                                             num_epochs=1, \n","                                             compression_type=\"GZIP\")\n","\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(_MODEL_DIR)\n","\n","\n","ranker.fit(train_dataset,\n","           validation_data=vali_dataset,\n","           steps_per_epoch=100,\n","           epochs=100,\n","           validation_steps=1,\n","           callbacks=[tensorboard_callback])\n"],"metadata":{"id":"Lgcg9WvFR9rE"},"id":"Lgcg9WvFR9rE","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"Input_Pipeline.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}